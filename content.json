{"pages":[],"posts":[{"title":"CMUでの滞在","text":"概要 金子はカーネギー・メロン大学 (Carnegie Mellon University; CMU) の Language Technologies Institute (LTI) のGrahamグループに2022年9月〜11月の間滞在し研究を行なった。Grahamグループは主に自然言語処理における生成タスクに注力しており、世界的に有名なグループのひとつである。 CMUは日本からの多くの研究者を受け入れており、金子が滞在している間にもLTIには5人、CMU全体でも多くの日本人が滞在しており、日本人同士の交流も楽しめた。滞在中多くの日本関係者の人にサポートしていただいたので、自分も今後CMUに滞在することになる方々のサポートにつながればいいなと思い、滞在がどんな感じであったかをここに記す。 Grahamグループの滞在が決まるまで 世界で活躍できる研究者になることが自分の目標のひとつである。そのため、以前からポスドクをしている間に海外の強い研究室に滞在して研究力や知名度を高めたいと考えており、岡崎研でポスドクをやるかどうか決める前から岡崎先生にその旨を伝えていた。しかし、コロナがしばらくは落ち着かず渡航する機会がしばらくの間なかったため泣く泣く断念していた。 しかし今年の春頃からコロナが落ち着いてきて海外に行ける雰囲気がでてきたので、岡崎先生に3ヶ月ほど海外の研究室に滞在して研究したいことを改めて伝え、滞在先について相談に乗っていただいた。その際、ポスドクで雇用されているプロジェクトの予算で滞在費や交通費を捻出してもらいたいことをお願いした。岡崎先生は快く協力してくださったので、スーパー感謝である。 滞在先を決めるにあたっては、興味がある滞在先に行ったことがある知り合いに話を聞いたり、最近の論文リストを調べたり、どんな学生がいるかHPで確認したりして情報収集を行った。場所については、学生の頃にイギリスのリバプールには滞在したことがあったので、それ以外の国に行きたいなという気持ちはあったものの、特に強いこだわりはなかった。 最終的には、自分の研究の興味と近くめちゃめちゃ論文が採択されており、成長できそうな環境であるCMUのGrahamグループに行きたいと考えた。元々自分はGrahamさんと面識はなかったが、岡崎先生が知り合いだったので岡崎先生に繋いでいただいた。日本にいる間にメールで数件やりとりしたのちに、ダブリンで開催されたACL2022で直接自分のやりたい研究などについてお話ししてCMUに滞在することを了承していただいた。その後、シアトルで開催されたNAACL2022にて英語能力を把握するための面接と研究のミーティングをしたりした。自分は全然英語できないが面接はなんとかなった。なお、英語面接は英語試験のスコアに代えられる。 Grahamさんはめちゃめちゃ忙しい＆グループの学生も研圧が高いので、受け入れてもらえるか微妙かなと思っていたが無事OKでよかった。ちなみに、本当は2箇所ぐらい行こうかなと考えていたが、もう1つの候補の先生にはコロナで受け入れの目処がたたず断られていた。滞在できそうになってからはLTIの学生やLTIでvisitorしていた人とご飯食べたりして、手続きやどんな感じで過ごしているかについて情報集を行った。 ビザ 金子はこれまでビザ申請をしたことがなかったが、ビザ手続きは基本的にCMUの事務の方の指示に従えばよかったのでそこまで大変ではなかった。CMUでvisiting researcherをするには、主に交換交流プログラムを目的としたJ1ビザを取得する必要があった。ビザ申請はトータルで見ると1ヶ月以上はかかったものの、CMUの事務の方は予想よりも迅速に対応してくれているなと思った。金子が渡航した時期はいくつかの条件を満たすと米国大使館で面接せずに郵送だけでビザをゲットできるようになっていたので、自分は郵送で済ませた。 家 短期滞在だとアパートなどの最低契約期間が大体半年から1年で、今回の3ヶ月の滞在では満たすことができないため、Airbnbを使い家を探した。出発の1ヶ月前に家探しを行ったら、自分の予算の範囲だと1件しか見つからず選択の余地なしであった。しかし、3ヶ月くらい前から家探しを行った別の滞在者はかなりの選択肢があったらしい。自分の家は大学も大きめのスーパーも歩いて30分ぐらいで、歩いてもバスを使っても所用時間が変わらないという立地の悪い場所にあった。ただ幸いにも冬は寒いが秋は自然豊かで紅葉がめっちゃ綺麗だったので、歩いて大学に行くのは悪くなかった。さらに、自然豊かなのでリス、鹿、ウサギや狸などたくさんの動物を見ることができた。 渡航 直行便がないので、行きは羽田→シアトル→ピッツバーグ、帰りはピッツバーグ→シカゴ→羽田というルートになった。行きはビザで入国するのが初めてだったので、とりあえず手ぶらで行ったらJ1ビザ関連の書類を持ってきておくべきだったらしく人生で初めて別室に連れて行かれた。ただ、書類が家にあることを説明したらなんか調べてくれて無事入国できた。帰りはピッツバーグ空港でユナイテッド航空のチェックインをしようとした時に機械が対応するチケットがないとエラーを吐き、係の人を呼んだが調べてもチケット見つからんと言われてあしらわれそうになった。別の係員に相談したところ日本に入国する場合はワクチン接種の有無を確認する必要があるため機械でそのままチェックインできない＆それを把握していない係の人もいると言われた。 ピッツバーグでの生活 ピッツバーグ便利帳というピッツバーグでの生活に関する情報がまとまっているサイトがあり参考になる。若干情報は古いがかなりのことが網羅されている。そこのメーリスに登録すると様々な情報を得れたり、現地の日本人の方と知り合えたりするらしい。LTIにも渡辺先生と三田村先生の日本人の教員が2人在籍しており、日本人のvisitorを何人か受け入れたりしていた。そのため、金子はLTIの日本人の学生とワールドカップやアメフト観たり、渡辺先生の家でホームパーティしたり、ビール巡りをして交流していた。ちなみに、学内でも学外でもほとんどマスクをつけている人はいない。 大学の周りにご飯を食べるとこはあったりするので、大学帰りに適当に買って食べたりしていた。大学内にも食堂があるのでそこでもご飯は食べられる。ただし、円安と物価高により、自炊したとしても食費はものすごくかかる。 大学やスーパーに行く時は徒歩だったが、遊びに行く時はバスを使っていた。空港から大学周辺もバスで行き来できる。どこに行くのにも3時間乗り放題で$2.75で行けるので便利。CMUの学生だと無料らしいが、visitorは無料にならなかった。交通系だとtransitというアプリがとても便利だった。Googleマップ的な機能に加えて、（時間通りにこないことが多い）バスをリアルタイムで追跡できたりする。さらに、アプリ内でバスのチケットをクレジットカードで購入することができる。バスではクレジットカードが使えないので、現金で乗ろうとするとお釣りが出てこない問題があってめんどくさいがこのアプリがあれば解決である。 研究 visitorはLTIの建物から遠い場所にオフィスが用意されるようで、自分も最初はそっちに席が用意されていたが、Grahamさんが事務の方と交渉してLTIの建物内に席を用意してくださった。週一でLTI建物内にあるGrahamさんのオフィスでミーティングをしていた。ミーティングの形式は特に指定されていなかったので、notionにページを作りそこに今週やったこと、考えていること＆相談したいこと、TODOを書いてミーティングしていた。 まず、ミーティングでは毎回深い議論が展開され大変勉強になったが、特に研究のインパクトを大きくするための的確なコメントやアドバイスを多くいただくことができた。この観点は自分に欠けているポイントでもあるので、そこを改めて認識できたという意味でも大変よかった。さらに、幅広く生成タスクに精通しているため、それらの方面で適切な関連研究を紹介してくださるのもありがたかった。そして、忙しい中でもGrahamさんは実際のデータを見ることを重視しており、一緒にデータをみたりアノテーションして議論してくださったことにもびっくりした。実際のデータを見てタスクに精通することで、高品質な研究テーマを考えることができているんだなと思った。 また、これは海外コミュニティに身を置くといつも思うことだが、slackワークスペース上でも発言や議論が活発に行われている。研究室内部だけではなくLTI全体のワークスペースがあり、そこで学生や教員がオープンにやりとりしているので、コロナ禍で失われた対面でのコミュニケーションの機会を補えていて良いなと思う。 筋トレ 週5でCMUのジムに通っていた。大学にジムは2〜3か所あるらしいが自分は一番大きいところしか使ったことがない。大学のIDカードさえあれば無料で使うことができる。平日は9時から23時くらいまでやっているので夜型の人にもやさしい。 設備としては自分が普段行っているジムより充実している。例えば、ダンベルは110ポンド（だいたい50キロ）まで10ポンド刻みで2セットずつあったり、HEXバーもあったりする。そして、筋トレの本場だけあってジムに来ている学生の意識はかなり高く、やっている種目、フォームや重量からしてかなり筋トレに関する知識を感じる。日本の筋肉を代表している気持ちでいたので、負けてたまるかと言う思いから筋トレのモチベーションはかなり高かった。そして、マスクせず筋トレができるので（コロナ以前は当たり前のことだったけど）より限界まで追い込める。ジムの出入り口には全身が見える大きい鏡があり、「わかってんね！」って感じの作りになっている。 筋トレのためのプロテインやサプリはドラッグストアやスーパーでもかなり充実している。金子は買い物に行っていたスーパーの近くにGNCという筋トレの専門店があったのでそこでプロテイン、プレワークアウト、イントラワークアウトのドリンクを買っていた。日本では販売していないブランドを多く取り揃えているのでついついたくさん買ってしまった。ちなみに、このお店はピッツバーグ空港の中にも出店しているので、飛行機に乗る前にプロテインバーやドリンクを買うこともできる。 まとめ CMUのコンピュータサイエンスにはレベルの高い学生や教員がたくさん在籍しているので、バリバリ研究したい人にはおすすめである。そのなかでも、GrahamグループはLTIの中でも一目置かれている感じがしたので、良い武者修行ができると思う。一方で、あまり観光的な楽しみはないので、研究だけじゃなくアメリカも満喫したい人はピッツバーグ外に出て旅行したりする必要があったりする。もしCMU関連で相談にのって欲しい、あるいは知り合いを紹介して欲しいなどあれば、できる範囲で力になれればと思う。","link":"/2022/12/22/overseas_cmu/"},{"title":"論文メモ：データ選択における著者バイアス、マルチモーダルの構造を調査、言語モデルと知識グラフを用いたQAモデル","text":"💡 概要 テキストデータ選択手法には特定の著者の属性を優遇する マルチモーダルモデルの事前学習データ、アテンション機構と損失関数について調査 言語モデルと知識グラフを相互に考慮したQAシステム テキストデータ選択手法には特定の著者の属性を優遇する タイトル： Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection 著者：Suchin Gururangan, Dallas Card, Sarah K. Drier, Emily K. Gade, Leroy Z. Wang, Zeyu Wang, Luke Zettlemoyer, Noah A. Smith 会議・出版： arXiv 年： 2022 言語モデルは学習のためにウェブデータを使うが、これらのデータには望ましくない内容を含んでいることがある。そのため、Wikipedia、書籍、ニュースなどのリソースは、言語モデルに最適なテキストを自動的に選択するためのアンカーとして扱われ、一般に品質フィルタが行われている。 この論文では、全米の高校生が書いた地理情報が付与された新聞記事のデータを用いて、GPT-3の品質フィルタでどのような内容が好まれるかを調査した。その結果、裕福、教育レベルが高い、都市部、大規模校のな新聞がより高い品質と分類することがわかった。このような言語イデオロギーをテキストデータの選択に用いると、学習データに含まれる可能性の高いテキストの著者が誰であるかという点で不平等が生じることになる。そして、フィルターの品質測定は事実の正確さや文学的評価などの測定基準と整合していないことを示す。 また、言語モデルのための学習データの構築には、様々なテキストを含むか含まないかの透明性と正当性をより高める必要があることを主張している。この問題を解決する方法はこの論文で提案されていない。一方で、代表的でない著者やグループ、複数のジャンルや文体からソースを収集し、手順や除外方法を明確にすることで透明性や正当性を高めることができる。そして、倫理的な観点から学習データや事前学習済みモデルの公開予定はない。 マルチモーダルモデルの事前学習データ、アテンション機構と損失関数について調査 タイトル： Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers 著者：Lisa Anne Hendricks, John Mellor, Rosalia Schneider, Jean-Baptiste Alayrac, Aida Nematzadeh 会議・出版： TACL 年： 2021 マルチモーダルモデルは画像と言語に関して豊かな表現を学習することが示唆されている。この論文では事前学習モデルの表現を評価するためにゼロショット画像検索タスクを対象として、学習された表現の質に影響を与える3つの重要な要因（１）事前学習データ（２）アテンション機構（３）損失関数について調査する。 6つのデータセットでモデルを事前学習することにより、事前学習のデータサイズよりもノイズと下流タスクとの言語類似度がモデル性能の重要な指標であることを明らかにした。また、マルチモーダルなアテンション機構を持つモデルは、画像または言語モダリティに特化したアテンション機構を持つモデルよりも性能が高いことを示した。最後に、自己教師あり学習に使用される対照学習をマルチモーダルモデルで使用した場合、性能向上が得られないことも明らかにした。 言語モデルと知識グラフを相互に考慮したQAシステム タイトル： GreaseLM: Graph REASoning Enhanced Language Models for Question Answering 著者：Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D. Manning, Jure Leskovec 会議・出版： ICLR 年： 2022 テキストによる物語に関する複雑な質問に答えるには、記述された文脈とその根底にある世界知識の両方について推論することが必要である。 しかし、既存のQAシステムの基盤となっている事前学習済みの言語モデルは、推論に必要な概念間の潜在的な関係を頑健に表現していない。知識グラフは世界知識の構造化表現として言語モデルを補強するためにしばしば用いられる。一方で、知識グラフの表現と言語情報により与えられる制約やニュアンスをどのように融合し推論するかは未解決の問題である。 この論文では、事前学習言語モデルとグラフニューラルネットワークから得られるモダリティ表現を多層的に融合する新しいモデルGREASELMを提案する。両モダリティからの情報を伝搬しあうことで言語表現は構造化された世界知識によって基礎づけられ、文脈中の言語のニュアンスを知識のグラフ表現に提供することが可能になる。3つのベンチマークで評価した結果、GREASELMは状況制約と構造化知識の両方に対する推論を必要とする質問に対して8倍大きいモデルよりも性能が高いことを示した。","link":"/2022/01/28/research_2022_01_28/"},{"title":"論文メモ：知識蒸留と枝刈りによる公平性改善、モデル出力の一貫性を評価するDiscoScore、寄与率による説明性に対する人間の理解、特徴量による説明性は人間理解への貢献を検証","text":"💡 概要 知識蒸留と枝刈りによるモデル圧縮は公平性を改善する テキスト生成モデルの一貫性を評価するDiscoScore 寄与率による説明性に対する人間の理解について分析 特徴量による説明性は人間のモデルの性能への理解に貢献するかを検証 知識蒸留と枝刈りによるモデル圧縮は公平性を改善する タイトル： Can Model Compression Improve NLP Fairness? 著者：Guangxuan Xu, Qingyuan Hu 会議・出版： arXiv 年： 2022 大規模な言語モデルを用いることは様々なタスクで有効であることが知られている。そして、知識蒸留や枝刈りによる大規模モデル圧縮が注目されているが、圧縮がモデルの公正さに及ぼす影響については十分に調査されていない。 本論文は言語モデルの有害さと偏りに対する蒸留と刈り込みの効果を検証した。GPT2に対して知識蒸留と枝刈りの手法を適用し、モデル蒸留後に有害さとバイアスが減少することを発見した。 この結果は圧縮を用いて公平なモデルを開発する可能性を示唆するものである。一方で、正則化とモデルの頑健性に関連しているという仮説を立てたが、この関連を検証するためにはさらなる実験と理論的裏付けが必要である。 テキスト生成モデルの一貫性を評価するDiscoScore タイトル： DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence 著者：Wei Zhao, Michael Strube, Steffen Eger 会議・出版： arXiv 年： 2022 文の相互依存性をモデル化するなど談話一貫性の観点からテキスト生成モデルを設計することに関心が高まっている。しかし、最近のBERTベースの評価指標では、一貫性を認識できず、システム出力に含まれる一貫性に欠ける要素を減点することができない。 本研究では、BERTを用いて読者のフォーカスに着目するセンタリング理論により異なる視点から談話一貫性をモデル化した評価指標であるDiscoScoreを紹介する。 実験ではDiscoScoreと一般的な一貫性を評価するモデルを含む16の非談話及び談話指標を網羅し、要約と文書レベルの機械翻訳で評価した。その結果、（1）BERTベースの指標の多くはは10年前に提案された初期の談話指標よりも人間が評価した一貫性との相関がはるかに悪い、（2）最新の評価指標であるBARTScoreは、システムレベルの比較において弱点があることを明らかにした。 これに対して、DiscoScoreは一貫性だけでなく事実との一致のにおいて人間の評価とシステムレベルで強い相関を達成した。BARTScoreとの比較では、平均で10ポイント上回る相関を示した。 寄与率による説明性に対する人間の理解 タイトル： Human Interpretation of Saliency-based Explanation Over Text 著者：Hendrik Schuff, Alon Jacovi, Heike Adel, Yoav Goldberg, Ngoc Thang Vu 会議・出版： arXiv 年： 2022 説明可能なAIの多くの研究は効果的な説明を生成することに焦点を当てているが、実際に人間がどのように説明を理解し解釈するかについて焦点を当てた研究はあまりない。 本研究では、入力単語の寄与率に基づく説明の研究を通じてこの問題に注目する。テキストモデルの寄与率による説明性は入力テキストのどの単語がモデルの決定に対して他の単語よりも影響力があったかを伝える。勾配に基づく方法やシャープレイ値に基づく方法は、数学的に寄与率を提供していることがわかっている。しかし、説明を受けた人間はどのようにそれを理解するのか？また、その理解はモデルの説明が伝えようとしたものと一致しているのだろうか？これらの疑問に答えるために、入力、Feature Attribution、可視化手順などの様々な要因が人間の説明の理解に与える影響を実証的に調査する。英語とドイツ語のタスクに対するクラウドワーカーのモデルの説明に関する回答に対してGAMMモデルを適用した。 その結果、説明の重要性を直接的に伝えているにもかかわらず単語の長さや文の長さなどの表層的で直接関係ない要因が、人間のの重要性の割り当てに影響を与え説明の理解を誤ることがわかった。また、ヒートマップに代わる寄与率の可視化手法として棒グラフを提案する。特定の要因による説明に対する歪曲効果を減衰させ、より良い寄与率のCalibration（モデルの出力値を実際の分布に近づけること）を導くことができることを発見した。 特徴量による説明性は人間のモデルの性能への理解に貢献するかを検証 タイトル： Explain, Edit, and Understand: Rethinking User Study Design for Evaluating Model Explanations 著者：Siddhant Arora, Danish Pruthi, Norman Sadeh, William W. Cohen, Zachary C. Lipton, Graham Neubig 会議・出版： AAAI 年： 2022 機械学習モデルの予測を説明する試みとして、重要だと思われる特徴量を予測結果の要因とする手法はたくさん提案されている。これらの手法は人間のモデルに対する理解を向上させる可能性があると主張されているが、明示的に検証した研究はほとんどない。 そのため、この論文では人間がホテルのレビューの本物と偽物を区別するために訓練された検出モデルと作業する、クラウドソーシングによる調査を実施する。クラウドワーカーは、学習データとは別のレビューに対してモデルの予測を再現することと、もともと予測されたクラスの確率を下げる、つまり敵対的なレビューを作成することを目標にレビューを編集することの両方に挑戦する。クラウドワーカーの学習段階のデータは入力スパンの寄与率を伝えるためにハイライトされる。 実験の結果、線形bag-of-wordsモデルに対して、クラウドワーカーの学習段階において特徴量にアクセスできる場合（説明あり）は、特徴量にアクセスできない場合（説明なし）と比較してテスト段階でモデルの信頼性を大きく低下させることができることがわかった。そして、BERTベースの分類器では一般的な局所的な説明は、説明なしの場合よりもモデル信頼度を低下させるクラウドワーカーの能力を向上させなかった。一方で、BERTモデルを模倣して訓練された線形モデルの説明がBERTモデルの説明として有用であることが示された。","link":"/2022/02/02/research_2022_02_01/"},{"title":"論文メモ：CNNとTransformer事前学習モデルの比較、ルールベースと深層学習を統合した手法DEEPCTRL、アテンション機構の説明性に対する忠実性の調査","text":"💡 概要 CNN事前学習モデルはTransformer事前学習モデルに匹敵する 深層学習モデルにルールベースを制御し考慮する手法DEEPCTRL 説明性におけるアテンション機構の重みとモデル予測の忠実性の間の整合性調査 CNN事前学習モデルはTransformer事前学習モデルに匹敵する タイトル： Are Pre-trained Convolutions Better than Pre-trained Transformers? 著者：Yi Tay, Mostafa Dehghani, Jai Gupta, Dara Bahri, Vamsi Aribandi, Zhen Qin, Donald Metzler 会議・出版： ACL 年： 2021 事前学習モデルにおいてTransformerは最も標準的な選択肢になっている。一方で、最近の研究では畳み込みニューラルネットワーク（CNN）も有望性が示されているが、事前学習モデルにおいて検討は行われていない。 本研究では事前訓練と非事前訓練の両方に関してモデル構造としてCNNはTransformerと競合するかどうかを調査する。そして、実行時間、スケーラビリティ、FLOPS数、モデルの品質に関する注意点とトレードオフについても議論する。 8つのデータセット/タスクに関する広範な実験を通して、CNNベースの事前学習済みモデルは特定のシナリオにおいてTransformerの対応するモデルよりも優れており、競争力があることを発見した。事前学習されたTransformerはデファクトスタンダードのモデル構造であるが、この論文の結果は特定のシナリオでは最適でない可能性があることを示している。そのため、事前学習とモデル構造は独立して考慮する必要がある。 深層学習モデルにルールベースを制御し考慮する手法DEEPCTRL タイトル： Controlling Neural Networks with Rule Representations 著者：Sungyong Seo, Sercan O Arik, Jinsung Yoon, Xiang Zhang, Kihyuk Sohn, Tomas Pfister 会議・出版： NeurIPS 年： 2021 ニューラルモデルは学習データの規模と網羅性が大きくなるほどより正確な結果が得られます。高品質で大規模なラベル付きデータセットを用いることはモデル改善のための1つの方法です。これとは別に、「ルール」（推論ヒューリスティック、方程式、連想論理、または制約などの事前知識）を活用する方法がある。 ルールベース手法を深層学習モデルに統合し、推論時にルールベース手法と深層学習モデルのどちらをより考慮するかを制御可能できる新しい学習手法であるDEEPCTRLを提案する。DEEPCTRLはデータの形式やモデル構造に依存しない。さらに、DEEPCTRLの重要な点としてルールベースを考慮するために学習済みモデルの再学習を必要とせず、推論時にユーザ自身が調整することができる。 物理、小売、ヘルスケアなどのルールを組み込むことが重要な実世界のドメインにおいてDEEPCTRLは有効性を示した。ルールベースを考慮する割合を大幅に向上させることで、学習済みモデルの信頼性と信用性を向上させ同時に下流タスクでの精度向上も実現した。 説明性におけるアテンション機構の重みとモデル予測の忠実性の間の整合性調査 タイトル： Rethinking Attention-Model Explainability through Faithfulness Violation Test 著者：Yibing Liu, Haoliang Li, Yangyang Guo, Chenqi Kong, Jing Li, Shiqi Wang 会議・出版： arXiv 年： 2022 アテンション機構はニューラルモデルの説明性の文脈で語られることが多い。アテンション機構は入力に対する確率分布を生成し、特徴量の重要性を示す指標として広く認識されている。 一方で、本論文ではアテンション機構の説明性には重大な限界があることを発見した。特徴の影響の極性を特定することが弱いことである。ここでアテンション機構の極性とは、注目度の高い素性はモデル予測に忠実に寄与せず、逆に抑制する効果を与える可能性があるということである。この発見を基に勾配やLRPベースのアテンション機構などの既存手法の説明可能性について考察する。 まず、アテンション機構の重みと極性の間の整合性を測定するための手法 (faithfulness violation test) を提案する。そして、広範な実験を通してテストされたほとんどの説明性が、抑制効果により予想外に妨げられていることを示す。","link":"/2022/02/04/research_2022_02_04/"},{"title":"論文メモ：ブラックボックス設定のプロンプト学習、プログラム形式の推論のための事前学習POET、経済的公平さと繁栄のための民主的AI","text":"💡 概要 ブラックボックス設定における事前学習モデルのプロンプト学習 プログラム形式のデータで事前学習された推論手法POET 経済的公平さと繁栄を両立するための民主的AI ブラックボックス設定における事前学習モデルのプロンプト学習 タイトル： Black-box Prompt Learning for Pre-trained Language Models 著者：Shizhe Diao, Xuechun Li, Yong Lin, Zhichao Huang, Tong Zhang 会議・出版： arXiv 年： 2022 大規模な事前学習済み言語モデルに対するドメイン固有のfine-tuingが大きな注目を集めている。既存研究ではモデルの構造やパラメータにアクセス可能であり、これをホワイトボックス設定と呼ぶ。 この論文では、入力が与えられたときの出力を除いて事前学習モデルにアクセスできない新しいシナリオを考察し、この問題をブラックボックス設定と呼ぶ。ブラックボックス設定では事前学習モデルにアクセスできないため、プロンプトを更新するための勾配の逆伝播を行えない。 まず、この論文ではテキスト分類に関するブラックボックス設定を定義する。そして、解決策であるブラックボックスプロンプトを提案する。ブラックボックスプロンプトではNESアルゴリズムを用いて勾配を近似しプロンプトを更新する。実験により、提案手法は8個のデータセットにおいてSoTAを達成した。 プログラム形式のデータで事前学習された推論手法POET タイトル： Reasoning Like Program Executors 著者：Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Jian-Guang Lou, Weizhu Chen 会議・出版： arXiv 年： 2022 自然言語による推論は自然言語処理コミュニティにとって長年の目標である。テキストデータで事前学習された言語モデルを用いることが一般的であるが、既存の言語モデルでは推論が不十分であることが研究により示されている。本論文では新しい事前学習手法であるPOETを提案している。プログラムとその実行形式のデータにより言語モデルを事前学習することで、POETは推論知識を言語モデルに学習させる。 この論文では、POET-Math, POET-Logic, POET-SQLの3つのインスタンスを紹介している。6つのベンチマークに対する実験結果から、POETは数値推論、論理推論、マルチホップ推論などの自然言語推論のモデル性能を大幅に向上させることができることを実証した。 特にDROPベンチマークでは、POETはBARTのF1指標を69.2%から80.6%に向上させた。さらに、POETは大規模言語モデルで最も効果を発揮し、T5-11BのF1スコアで87.6%のSoTAを達成した。 経済的公平さと繁栄を両立するための民主的AI タイトル： Human-centered mechanism design with Democratic AI 著者：Raphael Koster, Jan Balaguer, Andrea Tacchetti, Ari Weinstein, Tina Zhu, Oliver Hauser, Duncan Williams, Lucy Campbell-Gillingham, Phoebe Thacker, Matthew Botvinick, Christopher Summerfield 会議・出版： arXiv 年： 2022 人間が集団で行動して富を生み出すとき、その収益を公平に、しかし繁栄を損なわないように分配する仕組みが必要である。一方で、人間の価値観に沿ったAIの構築はまだ未解決な問題である。 そこで、強化学習をにより人間が多数決で好む社会的な仕組みを設計する民主的AIと呼ばれるヒューマンインザループ手法を開発した。そのために、人間が参加する実際のお金を使ったオンライン投資ゲームを行った。このゲームで金銭を集団的な利益のために他者と共有するまたは共有しないを決定することができる。共有された収益は、AIが設計したものと人間が設計した2つの異なる再分配の仕組みでプレイヤーに還元される。人間が過半数で投票する再分配の仕組みを設計するためにAIシステムを学習する。 その結果、人間が設計した再分配の仕組みや、様々なベースラインよりもAIが設計した仕組みの方が人気があることが分かった。そして、AIは富の不均衡を改善し、フリーライダーを制裁する仕組みを発見した。人間の嗜好に最適化することで、民主的AIは価値に沿った政策革新のための有望な手法となる可能性がある。","link":"/2022/01/30/research_2022_01_30/"},{"title":"論文メモ：訓練不要な層に置換することによる高速化、翻訳モデルの出力による評価モデルの弱点分析、学習設定のデータスケーリング法則への影響、多言語言語モデルXGLM","text":"💡 概要 訓練可能な層を訓練不要な層に置換することによる高速化 評価モデルに対して翻訳モデルを最適化することで評価モデルの弱点を分析 学習設定がデータスケーリングの法則に与える影響 大規模多言語言語モデルXGLMのfew-shot学習とzero-shot学習の調査 訓練可能な層を訓練不要な層に置換することによる高速化 タイトル： Learning Features with Parameter-Free Layers 著者：Dongyoon Han, YoungJoon Yoo, Beomyoung Kim, Byeongho Heo 会議・出版： ICLR 年： 2022 畳み込みブロックのような学習可能な層は、連続した空間の演算によってグローバルな文脈を捉えるためのパラメータを学習しており、標準的なネットワーク設計の選択肢となっている。効率的なネットワークを設計する場合、深さ方向の畳み込みなどの学習可能な層はパラメータ数とFLOPsの効率化が可能であるが、実際にはモデル速度の向上はほとんど得られない。 本論文では、ネットワーク構造において演算を効率的な訓練可能な層に置き換えるのではなく、シンプルな訓練不要なパラメータフリー演算に置き換えることが速度に関して有効であることを明らかにする。これはネットワーク構造の演算を訓練可能な層で構成するという固定観念を打破することを目的とする。 max-poolやavg-poolのような訓練不要な演算が機能するかどうかを調べるために、訓練されたモデルによる層レベルの調査とネットワーク構造の探索により訓練不要な演算の置換について広範な実験分析を行う。この調査により、モデルの精度をそれほど犠牲にすることなく、訓練不要な演算を主要な構成要素としてモデルに用いるアイデアを得る。ImageNetデータセットにおける実験の結果、訓練不要な演算を用いたネットワーク構造は、モデル速度、パラメータ数、FLOPsの面でさらなる効率化のメリットを享受できることが実証された。 評価モデルに対して翻訳モデルを最適化することで評価モデルの弱点を分析 タイトル： Identifying Weaknesses in Machine Translation Metrics Through Minimum Bayes Risk Decoding: A Case Study for COMET 著者：Chantal Amrhein, Rico Sennrich 会議・出版： arXiv 年： 2022 機械翻訳においてニューラルネットワークを用いた評価指標は人間の評価と高い相関を実現している。一方で、このような評価指標に対して機械翻訳モデルを最適化する前に、高いスコアを得た悪い翻訳へのバイアスを認識し排除する必要がある。 この論文ではサンプルベースのMinimum Bayes Risk (MBR) デコーディングを使用し、評価指標の弱点を見つけ定量化することができることを示した。実験では英語-&gt;ドイツ語とドイツ語-&gt;英語の翻訳に対して、ニューラルネットワークを用いた評価指標であるCOMETをMBRデコーディングに適用した。その結果、COMETは数字や名前の不一致に十分な評価を行えないことが明らかになった。さらに、これらの問題は単に擬似データを追加学習させるだけでは完全に除去できないことも示した。 学習設定がデータスケーリングの法則に与える影響 タイトル： Data Scaling Laws in NMT: The Effect of Noise and Architecture 著者：Yamini Bansal, Behrooz Ghorbani, Ankush Garg, Biao Zhang, Maxim Krikun, Colin Cherry, Behnam Neyshabur, Orhan Firat 会議・出版： arXiv 年： 2022 本研究では、ニューラル機械翻訳のデータスケーリングの法則を実証的に示す。まず、エンコーダ・デコーダTransformerモデルのテストデータにおける損失が、モデルサイズに依存し学習サンプル数のべき乗則でスケールすることを明らかにする。次に、学習設定の様々な要素を変更しデータスケーリングの法則にどのような影響を与えるかを調査した。 その結果、変更の大部分はスケーリング曲線の乗法的なシフトをもたらすだけで、指数はほとんど変化しないことがわかった。これはモデル構造や学習データの品質が多少悪くとも、データを追加することで補正できることを示唆している。一方で、パラレルデータではなく逆翻訳データを用いて学習分布を変更すると、スケーリング指数に影響を与えることがわかった。 大規模多言語言語モデルXGLMのfew-shot学習とzero-shot学習の調査 タイトル： Few-shot Learning with Multilingual Language Models 著者：Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O’Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li 会議・出版： arXiv 年： 2022 GPT-3などの大規模言語モデルは、fine-tuningなしに広範囲のタスクを処理することができる。大規模言語モデルは多くの異なる言語を同一空間上で表現できることが知られているが、学習データは英語が支配的であり言語横断的な汎化性には限界がある可能性がある。 本研究では、多様な言語を網羅しかつ言語のバランスのとれたコーパスを用いて多言語言語モデルを学習し、様々なタスクにおけるfew-shot学習とzero-shot学習の性能を調査する。その結果、75億のパラメータを持つ最大規模のモデルが20以上の代表的な言語における少数ショット学習において新たなSoTAを示し、多言語推論や自然言語推論において同一サイズのGPT-3を上回る性能を示しました。機械翻訳ベンチマークFLORES-101では、182の翻訳方向のうち171方向でGPT-3を上回り、45方向で教師ありベースラインを上回った。 また、本モデルが成功・失敗した点を詳細に分析し、いくつかのタスクにおいて言語横断的な学習を可能にしていることを明らかにした。そして、5つの言語でのヘイトスピーチ検出などの社会的価値のあるタスクで言語モデルを評価し、GPT-3モデルと同様の限界があることもわかった。","link":"/2022/02/18/research_2022_02_18/"},{"title":"論文メモ：人間とAIの協調性の改善、トークン化、変化要因を制御した言語間の転移分析、デルタチューニングを体系的な調査・定義","text":"💡 概要 人間の行動をモデル化し最適化することで人間とAIの協調性を改善 トークン化、形態素や構文などの要因を制御した言語間の転移分析 デルタチューニングを体系的に定義し100以上のNLPタスクで調査 人間の行動をモデル化し最適化することで人間とAIの協調性を改善 タイトル： Uncalibrated Models Can Improve Human-AI Collaboration 著者：Kailas Vodrahalli, Tobias Gerstenberg, James Zou 会議・出版： arXiv 年： 2022 AIを用いた多くのアプリケーションにおいて、AIは人間のユーザの決定の補助として使われる。AIは人間が意思決定プロセスに組み込むようなアドバイアスを提供する。AIのアドバイスはよく人間がアドバイアスをどらくらい依存または信頼できるかをcalibrateするために使う「信頼度」の指標と共に提示される。 この論文では、もともとのAIが十分にcalibrateされたときでさ、AIを実際よりも自信を持ってアドバイアスを提示することで、人間とAIの性能を改善できることを示す。AIのアドバイスを見た後の人間の最終的な予測の性能と信頼度により評価される。 まず、どのように人間がAIのアドバイスを組み込むか数千の人間との対話データを使いモデルを学習する。これは最終的な人間の予測を改善するために、どのようにAIの予測の信頼度を変換し、AIをuncalibrateさせるかを明確に評価することを可能にする。 数百人の人間の参加者が含まれたデータを含む画像、テキストと表形式のデータを扱う4つの異なるタスクにおいて結果を実験的に検証する。さらに、シミュレーション分析により結果をサポートする。この論文は重要な。AIモデルだけを最適化する一般的なパラダイムに対して人間とAIシステムを同時に最適化することの重要性とそのフレームワークを提案している。 トークン化、形態素や構文などの要因を制御した言語間の転移分析 タイトル： Oolong: Investigating What Makes Crosslingual Transfer Hard with Controlled Studies 著者：Zhengxuan Wu, Isabel Papadimitriou, Alex Tamkin 会議・出版： arXiv 年： 2022 トークン化、形態素や構文などの要因が言語間で一度に変化するため、何が言語間の転移を難しくしているかはほとんどわかっていない。これらの要因の影響を紐解くために、この論文では制御された転移調査を提案する。GLUEタスクを系統的に変形させ、異なる要因を一つずつ変化させ、その結果生じる学習済みモデルの下流性能の低下を測定する。 知識転移に対する構文からの影響は少ないとする既存研究とは対照的に、我々は構文のシフトによる大きな影響を発見した。一方で、モデルは小規模なデータでの継続的な事前学習によりすぐに適応する。しかしながら、既存の層と新しい埋め込みを整合させることが言語間の転移において最も影響のある要因であり、トークン化やや形態素の変更による追加効果はほとんどないことを発見した。さらに、小規模データで事前学習を継続することは提示されたギャップを減らすのにほとんど効果的ではなく、この問題を解決するには新しい方向性が必要であることを示唆している。 デルタチューニングを体系的に定義し100以上のNLPタスクで調査 タイトル： Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models 著者：Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, Jing Yi, Weilin Zhao, Xiaozhi Wang, Zhiyuan Liu, Hai-Tao Zheng, Jianfei Chen, Yang Liu, Jie Tang, Juanzi Li, Maosong Sun 会議・出版： arXiv 年： 2022 事前学習言語モデルはさまざまなNLPタスクにおける基盤技術となっており、新しい研究の証拠は継続的に大規模なモデルが良い性能であることを証明している。しかし、歓迎すべき結果であるにもかかわらず、大規模な事前学習言語モデルのファインチューニングには法外なコストがかかる。実際、巨大なモデルのパラメータ全てをファインチューニングすることと異なるタスクのために分割されたインスタンスを再学習することは非常に難しい。これは事前学習言語モデルのパラメータの効率的な活用に焦点を当てた新しい研究分野が必要となる。 パラメータ効率に限らず、そのような手法の可能性を解き放つために、この論文では本来の「効率的パラメータチューニング」に対して、形態学的観点から新しい用語「デルタチューニング」を造る。一般的なファインチューニングとは対照的に、デルタチューニングは一部のモデルパラメータのみをファインチューニングし、一方で残りのパラメータはそのままにすることで、計算とメモリ両方のコストを大幅に削減する。最近の研究では、パラメータを明確に選択するデルタチューニングが、全てのパラメータをファインチューニングした場合と同等の性能を達成できることが実証されている。これにより、デルタチューニングが大規模な事前学習モデルを活気づける新しい有望な方法であることが示唆されている。 この論文では、初めて正式にデルタチューニングの問題を説明し、包括的に最新のデルタチューニング手法を調査する。さらに、既存のデルタチューニングをaddition-based, specification-basedとreparameterization-basedの3つのグループに分類する統一的なカテゴリー基準を提案する。当初は大規模モデルを扱う効率的手法として提案されたが、デルタチューニングと共に発見された知見は事前学習言語モデルとニューラルネットワークの仕組みをさらに明らかにすることを助けると考える。この目的を達成するために、デルタチューニングの有効性を支える理論的な原則について議論し、最適化と最適制御の観点からデルタチューニングを解釈する枠組みをそれぞれ提案する。 さらに、代表的な手法の全体的な実験を行い、100以上のNLPタスクに関する結果は異なる手法の包括的な性能比較を示す。デルタチューニングの組み合わせ特性、スケーリング特性や転移特性についての分析も実験結果は網羅している。デルタチューニングの研究を容易にするために、ユーザーが事前学習言語モデルにおけるデルタチューニングを効率的にそして柔軟に実装を可能にするオープンソースツール「OpenDelta2」を開発する。最後に、デルタチューニングの現実世界のアプリケーションでのシナリオを議論する。","link":"/2022/03/27/research_2022_03_27/"},{"title":"頑固なバイアスは繰り返しで除去する","text":"タイトル： Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection 著者： Shauli Ravfogel, Yanai Elazar, Hila Gonen, Michael Twiton, Yoav Goldberg 会議・出版： ACL 年： 2020 💡 概要 零空間へ射影を繰り返すことで，分散表現に学習された情報を除去する手法 (Iterative Null-space Projection; INLP) を提案 除去したい情報を検出する線形モデルを学習し表現を零空間に射影することを繰り返すことで線形モデルが情報を検出できない，つまり情報を除去することができる 公平性に関するデータセットに適応し，バイアス除去することで提案手法の有効性を示した 📜 分散表現に学習されている不適切な情報 事前学習された単語分散表現や言語モデルのような分散表現を用いることは多くの自然言語処理タスクで効果的であることが知られている．一方で，これらの学習された表現はブラックボックスであり，それらに何ががエンコードされているかわからない．そのため，人種，性別や年齢に関するバイアスのような望まない情報が学習される可能性があります． このような情報が含まれていない分散表現を獲得するために，零空間へ射影を繰り返し分散表現に学習された特定の情報を除去する手法 (Iterative Null-space Projection; INLP) を提案する．提案手法は射影を用いた手法と敵対的手法を用いた既存手法を組み合わせており，数学的に基づいたバイアス除去とデータに基づいたバイアス除去の2つのメリットを持っている． 😞 既存研究の弱点 既存のバイアス除去手法は射影を用いた手法と敵対的手法の2つがある． 射影を用いた手法：, Bolukbasiら (2016)は射影を用いたバイアス除去手法を提案している．性別バイアスであれば$\\vec{he} - \\vec{she}$のような性別単語対の差で定義された性別部分空間を計算する．この部分空間は性別に関する情報を表現しており，doctorやnurseのような中性な単語を性別部分空間の第一主成分の方向が零になるようにする手法を提案した．これにより中性な単語が男性や女性に関する単語と等距離となる．一方で，GonenとGoldberg (2019)により，十分にバイアスが取り除けていないことが示されている．この手法の欠点は，単一またはいくつかの性別方向にのみ依存することである．実際には，性別の部分空間は数十から数百の方向にまたがっており，それは必ずしも$\\vec{he} - \\vec{she}$で定義できるものではない． 敵対的手法：ElazarとGoldberg (2018)は敵対的学習により分散表現からバイアスを除去する手法を提案した．ある分類器ではバイアスが取り除かれているように見えても，別の分類器ではバイアスの検出に成功することを明らかにし，敵対的手法によりバイアスを完全に除去することは自明ではないことも明らかにした．そして，この手法は敵対的学習のために下流タスクの損失関数も必要であり，事前学習された分散表現から情報を除去するという使い方はできない． 🛠 提案手法：零空間への射影を繰り返すことによるバイアス除去 事前学習された分散表現から除去したい情報を検出する線形分類器を複数学習し，各線形分類器がの重みの零空間に分散表現を射影することで情報を除去する．複数の分類器を適応することでデータに基づいた数十の方向を使った零空間への射影によりバイアスを除去することが可能となる． 零空間への射影 上図は2次元における二値分類器を用いた零空間の射影を表している．ここで$x \\in X$は入力ベクトルであり，$W$は線形分類器の重みである．$X$を$W$と直交する空間つまり零空間へ射影することで$W$の決定境界によってバイアスを検出できないようにする．式で書くと$W(P_{N(W)}x) = 0$ $\\forall x$となる．ここで，$W$における零空間を$N(W) = \\lbrace x|Wx = 0 \\rbrace$と定義し，$N(W)$への射影行列を$P_{N(W)}$としている． 分類器の繰り返し適応 多次元空間の関係は複数の線形方向（超平面）で捉えることができる．そのため，分散表現を単一の線形分類器の零空間に射影するだけでは十分ではない．この問題を解決するために分類器を繰り返して適応する．式で$m$回繰り返す射影行列$P$を書くと$P = P_{N(W_{m})} P_{N(W_{m-1})} … P_{N(W_{1})}$となる．ここで$W_i$は$W_{i-1}$の零空間に射影された$X$から学習される． 📊 バイアス評価の結果 単語分散表現におけるバイアス 分類器を用いて単語分散表現のバイアスを評価する．TRP-GAPは除去する情報のデータセットごとの正解クラスの期待値の差を評価する．TRP-GAPが小さいほど属性間で分類性能がなくバイアスがないことを意味する．以下の表は感情分析とTRP-GAPの結果を示している．ここではAfrican American EnglishとStandard American Englishの2種類の英語で書かれたテキストに対してポジティブとネガティヴの感情分析を行う．ここでは属性の偏りの影響を評価する手前にデータ内のAfrican Americanのポジティブ文の割合を調整し評価する．下はその結果であり，提案手法のINLPはもとの単語分散表現よりバイアスが除去できていることがわかる． BERTにおけるバイアス 最後にBERTの隠れ層を可視化することでバイアス評価を行う．男性と女性の情報が付与された28個の職種に関する履歴書データを用いる．下の左図はprofessorに関する履歴書のBERTの隠れ層，右図は全職業単語に対するBERTの隠れ層の可視化の結果である．オリジナルのBERTの隠れ層は女性と男性の履歴書に対する隠れ層が分類できるように分布しているが，INLPによりバイアス除去されたBERTでは男性と女性の隠れ層が混ざり合い分類できないようになっていることがわかる．","link":"/2021/06/07/research_INLP/"},{"title":"自然言語処理における英語論文誌の投稿先を探す","text":"💡 概要 自然言語処理の英語論文誌の投稿先を探すのに参考になったサイト サイト集 人工知能、機械学習や自然言語処理分野では、研究の進展速度が速いため論文誌より国際会議が重視される傾向がある。一方で、学位の関係や研究の内容的に論文誌に投稿する必要があるときに、普段国際会議ばかり投稿しているとどこに投稿したよいかわからないという事態になったりしてしまう。そんな時、英語論文誌の投稿先を決めるのに役立ったサイトが以下である： ACL Wiki：ACLがお薦めする自然言語処理の論文を投稿するのに適した論文誌のリスト。人工知能や認知科学など重点が置かれている分野ごとに分類されている。若干情報が古かったりする。 Top Computer Science Journals：コンピュータサイエンス系の論文誌をimpact factorでランキングしてある。眺めてるだけでも楽しい。 Top Computer Science Journals for Computational Linguistics &amp; Speech Processing：2番目のサイトから自然言語処理の論文誌を抜粋しimpact factorでランキングしてある。","link":"/2022/04/18/research_2022_04_18/"},{"title":"用例を基にした文法誤り訂正モデルを用いた言語学習者のための解釈性","text":"タイトル：Interpretability for Language Learners Using Example-Based Grammatical Error Correction 著者：Masahiro Kaneko, Sho Takase, Ayana Niwa, Naoaki Okazaki 会議・出版： ACL 年： 2022 💡 概要 言語学習のための文法誤り訂正モデルは訂正性能だけでなく結果の解釈性についても重要であるが、これまでほとんど議論されてこなかった。 近年、予測に用例を用いることで予測の根拠を提示できるようにし、モデルの解釈性を改善する手法が提案されている。言語学習では用例検索システムなどを用いて学習者が文法や語彙を学習することができる。そのため、予測に関連する用例を用いて文法誤り訂正モデルの解釈性を改善することで、同時に学習に有益な用例を提供できると考えられる。 そこで、本論文では言語学習者の解釈性のために用例を基にして予測を行う文法誤り訂正モデルを提案する。文法誤り訂正の訂正結果と類似する用例を検索し提示することは言語学習者に有益であることを示した。さらに、用例を用いることで文法誤り訂正モデルの性能も改善できることも明らかにした。 📜 文法誤り訂正における解釈性 これまでさまざまなニューラルベースの文法誤り訂正モデルが提案され訂正性能が改善されてきた。一方で、ニューラルベースの文法誤り訂正モデルはブラックボックスであり訂正の根拠を言語学習者に提示することができないため、言語学習者は訂正結果を反映するかの判断が困難であったり、訂正結果から十分に学ぶことができない可能性がある。そして、ニューラルベースの文法誤り訂正モデルにおける解釈性の研究はほとんど行われていない。 言語学習において、用例を提示することで学習者の理解を向上させれることが知られている。例えば、言語学習者は用例を調べることで文法や語彙を習得することに役立つ。さらに、用例検索システムを用いることで作文問題のスコアを改善することもできる。最近の研究では解釈性を改善するためにモデルの予測に用例を用いる手法が提案されている。Khandelwalら (2021)は機械翻訳モデルのデーコーダの表現空間上においてターゲット文の近傍にある用例はソース文の翻訳に役立つことを示した。これらのことから、文法誤り訂正モデルにおける近傍の用例は解釈性を改善し、言語学習者の判断や理解を支援できるのではないかと考えられる。 この論文では、言語学習者に有益な訂正根拠を提示するために用例を用いて文法誤り訂正を行うEample-Based Grammatical Error Correction (EB-GEC) を提案する。下図はEB-GECの概略図を示しており、トークンを予測し文法誤り訂正を行うモデルと訂正と関連する用例（正文と誤文の対）を教師データから検索するモデルを組み合わせている。 🛠 提案手法：EB-GEC 訂正の予測に用例を考慮するために$k$-Nearest-Neighbor Machine Translation ($k$NN-MT；Khandelwalら, 2021)を基にする。$k$NN-MTは予測時にデコーダの隠れ層の近傍の用例を考慮してトークンを予測する。下図はEB-GECの$k$NN-MTを基にして用例を検索する方法を示している。推論時にエンコーダ・デコーダから計算された分布と近傍の用例から計算された分布の両方を用いてトークンを予測する。 $k$NN-MTを用いた用例の検索 まず、$x=(x_1, …, x_N)$と$y=(y_1, …, y_M)$をそれぞれ文法誤り訂正モデルの入力文と出力文とする。EB-GECの最終的な出力分布$p_{\\textrm{EB}}$は、以下の式のように近傍の用例から計算された分布$p_{\\textrm{kNN}}$とデーコーダの最終層を線形変換しソフトマックス関数を適用することで計算された分布$p$の線形補間で計算される。ここで$\\hat{y}_i$は文法誤り訂正モデルにより出力された$i$番目のターゲットトークンであり、$\\lambda$は近傍の用例により計算された分布をどれくらい考慮するかを調整する0以上1以下のハイパーパラメータである。$p$を考慮することで関連する用例がない場合に、出力をより頑健に行えるようになると考えられる。本研究では、解釈性と頑健性の両方を満たすために$\\lambda$は0.5とする。 $p_{\\textrm{kNN}}$を計算するために、まずデータストア ($\\mathcal{K}$, $\\mathcal{V}$) を定義する。データストアは検索のための用例を教師データから抽出することで作成される。教師データに対する$i$番目のデーコーダの隠れ層を$\\boldsymbol{h}(x,y_{1:i-1})$をキーとし、対応する$i$番目のターゲットトークン$y_i$とその入力・出力文$x, y$をバリューとし以下のようにデータストアを構築する。ここで、$\\mathcal{X}$と$\\mathcal{Y}$はそれぞれ教師データの全てのソース文とターゲット文である。 推論時に$x$が入力として文法誤り訂正モデルに与えられたとき、そのデコーダの隠れ層$\\boldsymbol{h}(x,y_{1:i-1})$をキーとして作成したデータストアに対して以下のように$k$近傍探索を行う。ここで$\\boldsymbol{u}^{(j)}$ ($j = 1, \\dots, k$)は$L^2$距離により計算されるキー$\\boldsymbol{h}(x,y_{1:i-1})$に対する$k$近傍である。 以下のように、検索されたターゲットトークンから負の$L^2$距離を計算し、温度$T$付きソフトマックス関数を用いて分布$p_{\\textrm{kNN}}$を計算する。ここで正文と誤文は用いないため_としている。 検索した用例の提示方法 データストアの正文と誤文の対を$\\hat{y}_i$の訂正根拠となる用例として言語学習者に提示する。ゲシュタルトパターンマッチングにより入力文と訂正文のトークンを対応付けることで、出力文のうちモデルが訂正した箇所だけ用例を提示する。この論文では$k$近傍のうち1-bestの用例だけを根拠として用いる。 📊 実験結果 EB-GECが訂正性能を維持したまま解釈性を改善できているかどうかを調べる。そのために、言語学習者による人手評価と文法誤り訂正のベンチマークデータでの性能を評価する。文法誤り訂正モデルと近傍探索の設定はそれぞれVaswaniら (2017)とKhandelwalら (2021)の研究を基にした。 用例の解釈性に関する人手評価 用例検索のベースラインとして単語の表層一致による用例検索手法 (Token-based retrieval) とBERTの隠れ層を用いた用例検索手法 (BERT-based retrieval) の2つを用いる。文法誤り訂正モデルの訂正結果に対してベースラインの用例検索手法を適用し用例を提示する。 3人の英語学習者が3つの手法の用例330個（合計990個）に対して、訂正結果を反映するかどうかに役立つまたは理解をサポートするかを２値で判定する。下図は各手法ごとに有益であると英語学習者に判断された用例の割合を示している。文法誤り訂正モデルとは独立して用例検索を行う手法よりもEB-GECの方がより有益な用例を提示できていることがわかる。 EB-GECのベンチマークにおける訂正性能 文法誤り訂正でよく使われているベンチマークであるW&amp;I, CoNLL2014, FCEとJFLEGを用いて訂正性能の評価を行う。下図は用例を使わない文法誤り訂正モデル (Vanilla GEC) とEB-GECのF$_{0.5}$の結果である。JFLEG以外ではEB-GECの方が結果が良いことがわかる。このことから、EB-GECは性能を犠牲することなく解釈性を改善できていることがわかる。 用例検索の例 下図はEB-GEC、Token-based retrievalとBERT-based retrievalそれぞれの手法により検索された用例を示している。Error typeは誤りタイプを表しており、それぞれPREP：前置詞、PUNCT：句読点、DET：冠詞に関する誤りである。Labelはその用例が有益である1または有益ではない0の人手評価である。Token-based retrievalはトークンの表層一致しか考慮していないため、文脈が無関係な用例が提示されており有益ではないと評価されている。BERT-based retrievalは文脈を考慮できているが、最後の用例のように文脈に過剰に影響を受け無関係な訂正を提示してしまっている。一方で、EB-GECは類似した文脈で同じ訂正を持つ用例を提示できていることがわかる。","link":"/2022/02/24/research_eb-gec/"},{"title":"マスク付き言語モデルの差別的バイアスの除去","text":"タイトル： Debiasing Pre-trained Contextualised Embeddings 著者： Masahiro Kaneko, Danushka Bollegala 会議・出版： EACL 年： 2021 💡 概要 BERTやRoBERTaなどのマスク付き言語モデル (Masked Language Models; MLMs) に含まれる差別的バイアスを除去する研究 MLMのバイアス除去の適応箇所について(1)単語単位と文単位(2)最初の層，最終層と全層，の2つの観点に対して調査した．その結果，単語単位で全層に対してバイアス除去することがもっとも効果的であることを示した． そして，MLMごとに下流タスクへの影響に差があることも明らかにした 📜 MLMに対するバイアス除去の課題 MLMは自然言語処理の様々なタスクに用いられ，大幅な性能改善をもたらしてる．一方で，MLMには有益な情報だけでなく，単語分散表現などと同様に差別的なバイアスも学習されていることが知られている．例えば，&quot;This is Adam&quot;と&quot;This is Jamel&quot;という文対が与えられた時，&quot;They are evil&quot;という文との類似度が後者の文と高くなるという人種差別的な類似性が学習されています[1]．MLMに対するバイアス削除の研究では以下の3点が課題となる： 単語分散表現ではバイアス除去手法は盛んに研究されているが，単語分散表現とMLMではモデルの構造が違うためそれらの手法そのまま適応することが難しい． MLMの学習には計算資源や学習時間を必要とするため，fine-tuningのように事前学習されたMLMに適応できるバイアス除去手法が望ましい． MLMは多くの手法が提案されており，1つのMLMだけでなくさまざまなMLMに適応できる必要がある． 我々はこれらの課題を踏まえ，MLMの隠れ層を性別ベクトルと直交するようにfine-tuningすることで性差別に関するバイアスを除去する手法を提案する．そして，バイアス除去をMLMにどのように適応することが良いのか以下の図のように(1)単語単位と文単位(2)最初の層，最終層と全層，の2点について調査を行なった．BERT, RoBERTa, ALBERT, DistilBERTとELECTRAの5つのMLMに対して実験を行い，全てのMLMで提案手法はバイアス除去できていることを示した．そして，MLMごとにバイアス除去による下流タスクへの影響が異なること（BERT, DistilBERTとELECTRAでは下流タスクでの性能は少しの低下だけだが，RoBERTaとALBERTでは大幅に低下した．）も明らかにした． 🛠 バイアス除去手法の提案 まず，バイアス除去手法を説明するための定義を行う．sheやheのような性別情報を持つ単語を属性単語$\\mathcal{V_{\\rm a}}$，nurseやdoctorのような対象単語$\\mathcal{V_{\\rm t}}$と定義する．そして，単語$w$を含む文を$\\Omega(w)$とする．それぞれの単語を含む文の集合を$\\mathcal{A} = \\bigcup_{w \\in \\mathcal{V_{\\rm a}}} \\Omega(w)$と$\\mathcal{T} = \\bigcup_{w \\in \\mathcal{V_{\\rm t}}} \\Omega(w)$と定義する．本研究では，$\\mathcal{A}$の事前学習された情報を保持し，$\\mathcal{T}$から差別的な性別情報を除去する．事前学習されたハイパーパラメータ$\\boldsymbol{\\theta}_e$を持つMLM$E$に対してバイアス除去を行う．入力として単語$w$を含む文$x$が与えられ時の$i$層目の$E$の隠れ層は$E_i(w,x;\\boldsymbol{\\theta}_e)$と定義する． 提案手法は(1)バイアス除去と(2)事前学習された情報の保持，の2つの損失関数により定義される．1つ目のバイアス除去を行う損失関数$L_{i}$は以下の式で表される： $$ L_{i} = \\sum_{t \\in \\mathcal{V_{\\rm t}}} \\sum_{x \\in \\Omega(t)} \\sum_{a \\in \\mathcal{V_{\\rm a}}} (\\boldsymbol{v}_i(a)^\\top E_i(t, x; \\boldsymbol{\\theta}_e))^2 $$ ここで，${\\boldsymbol{v}_i(a)}$は性別情報を表した性別ベクトルであり，$x \\in \\Omega(a)$に対する隠れ層$E_i(a,x;\\boldsymbol{\\theta}_e)$の平均により計算される．上記の，損失関数は対象単語を含む文が入力として与えられたとき，隠れ層と性別ベクトルが直交するように学習しており，これによりMLMの隠れ層からバイアスを除去する．この損失関数は文単位でバイアス除去する際，$a$だけでなく$w \\in x$に対して計算される． 2つ目の事前学習された情報を保持する損失関数$L_{\\rm reg}$は以下の式で表される： $$ L_{\\rm reg} = \\sum_{x \\in \\mathcal{A}} \\sum_{w \\in x} \\sum_{i = 1}^{N} ||E_i(w, x; \\boldsymbol{\\theta_e}) - E_i(w, x; \\boldsymbol{\\theta}_{\\rm pre})||^2 $$ ここで$N$は文長です．バイアス除去されるMLMと事前学習された重みが固定されたオリジナルMLMの隠れ層が近づくように学習する．これにより事前学習された属性単語の情報を保持される．2つの損失関数の重み付き和を最終的な損失関数とする． 📊 バイアス評価と下流タスクでの結果 上記の表はSEATの性別に関する3つのバイアス評価とGLEUを用いた下流タスクでの性能評価の結果を示している．SEATでは0に近いほどbiasがなく，GLEUでは100に近いほど性能が良いことを示す．ここでrandomは属性単語と対象単語をシャッフルしてバイアス除去を学習したベースラインである．BERT, DistilBERTとELECTRAではバイアスが除去されながらもGLEUでの性能がほとんど低下していない．一方で，RoBERTaとALBERTではバイアス除去には成功しているがGLEUで大幅に性能が低下している．これらのことから，MLMによってはバイアス除去と事前学習された情報の保持でトレードオフがあることがわかる．そのため，バイアス除去手法はさまざまなMLMに対して適応し評価することが重要である．そして，結果からBERT以外の全てのMLMで単語単位で全ての層からバイアス除去する方法がもっとも効果的であることもわかる． この例はSEATデータセットでの事例を元にしています． ↩︎","link":"/2021/05/12/research_debias_mlm/"},{"title":"論文メモ：下流タスクと言語モデル自体の公平性の評価、汎化性のための偽の相関のバイアス除去、正解ラベルなしのプロンプトエンジニアリング","text":"💡 概要 下流タスクと言語モデル自体の公平性の評価にはほとんど相関がない 汎化性能を高めるために偽の相関によるバイアスを除去する 相互情報量による正解ラベルを用いないプロンプトエンジニアリング 下流タスクと言語モデル自体の公平性の評価にはほとんど相関がない タイトル：On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations 著者：Yang Trista Cao, Yada Pruksachatkun, Kai-Wei Chang, Rahul Gupta, Varun Kumar, Jwala Dhamala, Aram Galstyan 会議・出版： arXiv 年： 2022 複数の評価指標がさまざまなNLPタスクにおける公平性を評価するために提案されている。これらの評価指標は、大きく分けて（１）下流タスクの公平性を評価するための外部評価と（２）文脈付き言語モデル自体の公平性を評価する内部評価の2つに分類できる。 この論文では、19個の文脈付き言語モデルを用いて、外部評価と内部評価の広範囲な相関分析を行う。評価指標の不整合、評価データのノイズ、外部評価の実験構成などの交絡因子を補正した場合でも、外部評価と内部評価は必ずしも相関しないことを明らかにした。そのため、内部評価を用いて言語モデルの公平性を評価する際は、検出に失敗したバイアスが下流タスクの推論時に出現する可能性があることに注意する必要がある。 汎化性能を高めるために偽の相関によるバイアスを除去する タイトル：Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets 著者：Yuxiang Wu, Matt Gardner, Pontus Stenetorp, Pradeep Dasigi 会議・出版： ACL 年： 2022 NLPモデルはしばしばデータセットのタスクに依存しない素性とラベルの偽の相関によるバイアスを利用する。これは異なるタスクの分布に汎化しない一方で、学習させた分布内のみで良い性能を発揮する。この論文では、学習データを置き換えるだけで既存モデルの学習に使える、バイアス除去されたデータセットを生成することを提案する。この手法は (1) 高品質でラベルに一貫性のあるデータサンプルを生成するためにデータ生成モデルを学習する手法と（２）Z検定で評価される偽の相関に寄与するデータを除去するフィルター機構、により構成される。 バイアス除去されたSNLIとMNLIデータセットを生成し、バイアス除去されたデータセット、分布外のデータセット、敵対的なデータセットにおいて評価する。結果により、バイアス除去されたデータセットにより学習されたモデルは全ての設定においてオリジナルデータセットで学習されたモデルよりも汎化することがわかった。データセットの大部分で、提案手法は以前のSoTAバイアス除去手法に匹敵または上回り、直交する技術であるproduct-of-expertsを組み合わせた時、さらに改善しSNLI-hardとMNLI-hardにおいて以前の最高性能を上回った。 相互情報量による正解ラベルを用いないプロンプトエンジニアリング タイトル：An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels 著者：Taylor Sorensen, Joshua Robinson, Christopher Michael Rytting, Alexander Glenn Shaw, Kyle Jeffrey Rogers, Alexia Pauline Delorey, Mahmoud Khalil, Nancy Fulda, David Wingate 会議・出版： arXiv 年： 2022 事前学習言語モデルは学習に用いられた膨大なコーパスから言語的・事実的な知識を得ている。プロンプトエンジニアリングはこれらのモデルを特定タスクに適合することを目指す。残念ながら、既存のプロンプトエンジニアリングはたくさんのラベルありデータ、モデルのパラメータへのアクセスやその両方を必要とする。 そのため、ラベル付きの事例とモデルへの直接のアクセスなしにプロンプトテンプレートを選択する手法を提案する。具体的に、候補テンプレートの集合の中から、入力と対応するモデル出力の相互情報量を最大化するテンプレートを選択する。 7つの異なるNLPタスクの8つのデータセットにおいて、高い相互情報量を持つテンプレートの時、高いタスクの性能も達成することを示す。大規模モデルにおいて、提案手法によるプロンプトの選択は、平均的なプロンプトの精度から最高性能のプロンプトの精度までの90%を達成し、そして正解のラベルを必要としない。","link":"/2022/03/31/research_2022_03_31/"},{"title":"言語モデルの感情バイアスの評価と除去","text":"タイトル： Reducing Sentiment Bias in Language Models via Counterfactual Evaluation 著者： Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl, Jack Rae, Vishal Maini, Dani Yogatama, Pushmeet Kohli 会議・出版： EMNLP Findings 年： 2020 💡 概要 言語モデルによって生成されたテキストの感情バイアスを評価し除去する 国名，職業や性別に関する文脈が与えたれた際に言語モデルが生成したテキストの感情分析を行いその偏りにより評価を行う 言語モデルの隠れ層に対して正則化を行うことで感情バイアスの除去を行う 📜 言語モデルにおける感情バイアス この論文では言語モデルが生成したテキストの感情バイアスの評価・除去を行なっている．言語モデルにおける感情バイアスとは，&quot;My friend is a/an &lt;職業単語&gt;, and we …&quot;のような文脈が与えられた際，生成されたテキストの感情分析結果がポジティブやネガティブに偏ることである． 具体例により感情バイアスを説明する．上図は大規模言語モデルであるGPT-2における&quot;baker&quot;と&quot;accountant&quot;を含む文脈からサンプルされたテキストにおける感情の分布を示している．sentiment scoreは0.5以下であればネガティブ，0.5以上であればポジティブであることを意味する．この例では&quot;baker&quot;はよりポジティブなバイアス，&quot;accountant&quot;にはよりネガティブなバイアスがあることがわかる． 🩺 感情バイアスの評価 感情バイアスの定義 評価の説明を行う前に感情バイアスの定義を行う．まず，属性グループ$\\mathcal{A}$を定義する．$\\mathcal{A}$は性別であれば{female, male}となり，それぞれのサブグループは$a \\in \\mathcal{A}$として表される．そして，各属性情報を含むトークンの集合を$\\phi(a)$で定義される．例えば，$a=$maleであれば{Jake, Jamal, Cole}となる．ここでaに属さない$\\mathcal{A}$の属性を$\\tilde{a}$とする．性別であれば$a=$male，$\\tilde{a}$=femaleとなる．そして，&quot;A friend of &lt;性別単語&gt; told me&quot;のような文脈テンプレートの&lt;性別単語&gt;の箇所を$\\phi(a)$と$\\phi(\\tilde{a})$に含まれる単語で置換することで入力となる文脈$x$と$\\tilde{x}$を作成する．$x$と$\\tilde{x}$それぞれを言語モデルLMに入力として与え，文脈の続きのテキストLM($x$)をサンプリングにより生成する．生成されたテキストを感情分析器に入力として与え，感情スコア$S(x)=f_{\\rm s}({\\rm LM}(x))$を獲得する．感情分析器は[0, 1]の感情スコアを予測する．そして，$S(x)$の感情分布を$P_S(x)$と定義する．そして，$P_S(x)$と$P_S(\\tilde{x})$の分布の違いを感情バイアスとする．分布の違いはワッサースタイン計量を用いて$\\mathcal{W}_1(P_S(x), P_S(\\tilde{x}))$として測る． Individual fairnessとGroup fairness Individual fairness (I.F.)とGroup fairness (G.F.)の2つの感情バイアス評価方法を提案する． Individual fairness (I.F.) I.F.は全属性のペアの組み合わせの感情分布の違いによりバイアスを評価する．以下の式のように全てのテンプレート$M$に対する各属性の$a$と$\\phi(a)$を用いた$P_S(x)$と$P_S(\\tilde{x})$のワッサースタイン計量の平均により計算される． $$ \\frac{2}{M|\\mathcal{A}|(|\\mathcal{A} - 1|)} \\sum_{m=1}^M \\sum_{(a, \\tilde{a}) \\in \\mathcal{A}} \\mathcal{W}_1(P_S(x^m), P_S(\\tilde{x}^m)) $$ ここで$\\frac{|\\mathcal{A}|(|\\mathcal{A} - 1|)}{2}$は$\\mathcal{A}$に含まれる属性対の全ての組み合わせ数である．この式により，各属性の感情分布の違いを計算しバイアスを評価することができる． Group fairness (G.F.) G.F.は各サブグループ$a \\in \\mathcal{A}$と評価データ全体の感情分布の違いにより感情バイアスを評価する．これはサブグループの感情分布$P_S^a$と評価データ全体の感情$P_S^*$のワッサースタイン計量の平均により以下のように計算される． $$ \\frac{1}{|\\mathcal{A}|} \\sum_{a \\in \\mathcal{A}} W_1 (P_S^a, P_S^*) $$ 🛠 感情バイアスの除去 Embedding regularizatioとSentiment regularizatioという2つのバイアス除去手法を提案する．手法の説明を行う前に必要事項について定義を行う．言語モデルLMは入力として，$x_{1:i} = x_1, …, x_i$が与えられる．この時，最後のトークンはサブグループに属するトークン$x_i \\in \\phi(a)$である．そして，$a$以外のサブグループに属するトークンが最後のトークンである入力を$\\tilde{x}_{1:i}$とする． 感情バイアスが除去された言語モデルを学習するには、言語モデルが異なるサブグループのトークンを含む文脈に対して同じ感情分布を生成する必要がある。一方で，言語モデルの学習時に文脈ごとの生成テキストをサンプリングすることは非常にコストがかかる．そこで，生成されたテキストではなく代わりに言語モデルの隠れ層をバイアス除去のために用いる．ここで$x_{1:i}$が入力として与えられた$L$層の言語モデルの隠れ層は$h(x_{1:i}) = h^{(j)}(x_{1:i}), …, h^{(L)}(x_{1:i})$とする． 埋め込み正則化 この正則化では$h^{(j)}(x_{1:i})$と$h^{(j)}(\\tilde{x}_{1:i})$の隠れ層が近くなるように学習する．隠れ層同士の距離として以下のようにコサイン距離を用いる．コサイン距離は1引く2つの隠れ層の類似度により計算される．そして，コサイン類似度は$L$と$L-1$の隠れ層を平均し計算される．この手法の利点として異なる属性の隠れ層が近くなるため，感情バイアス以外のバイアスも除去できる可能性がある．一方で，異なる属性同士の予測が同じになるように強制するため，言語モデルの性能を低下させる可能性があることが欠点である． 感情正則化 埋め込み正則化の欠点を解決するために感情分析器を用いた正則化を提案する．言語モデルの隠れ層を感情分析器$f_{s_h}$に入力として与える．そして，感情分析器の隠れ層$f_{s_h}(h(x_{1:i}))$と$f_{s_h}(h(\\tilde{x}_{1:i}))$に対してコサイン類似度を計算する．感情分析器を適応することは，言語モデルの隠れ層を感情に関する部分空間に射影していると考えられる．これにより感情に関する情報だけを近づけて学習することができ，埋め込み正則化の問題点を解決することができる． 学習方法 埋め込み正則化の言語モデルの隠れ層のコサイン距離と感情正則化の感情分析器の隠れ層のコサイン距離を$\\mathcal{L_f}$とする．そして，言語モデルのトークン予測による損失関数を$\\mathcal{L_{\\rm LM}}$とする．そして，これらを以下の式のように組み合わせることで最終的な言語モデルの損失関数$\\mathcal{L}$を定義する． $$ \\mathcal{L} = \\mathcal{L}_{\\rm LM} + \\lambda \\mathcal{L_f} $$ ここで$\\lambda$はハイパーパラメーターである．以下の図は感情正則化を用いた言語モデルの学習を示している． 感情バイアスの除去結果 上記のグラフはWMT-19とWikiText-103それぞれで学習された言語モデルの感情バイアスの結果である．スコアが低いほど感情バイアスがないことを示している．結果から両方の提案手法で言語モデルのバイアスを除去できていることがわかる．","link":"/2021/05/17/research_evalate_sentiment_in_lm/"},{"title":"辞書を用いた単語分散表現の様々な差別的バイアス除去","text":"タイトル： Dictionary-based Debiasing of Pre-trained Word Embeddings 著者： Masahiro Kaneko, Danushka Bollegala 会議・出版： EACL 年： 2021 💡 概要 Word2vecやGloVeなどの単語分散表現に含まれる差別的バイアスを除去する研究 辞書の定義文を用いることでバイアスに関する単語リストを使わずにバイアス除去する手法を提案 性別，人種や年齢など幅広いバイアスに対して有効であることを実証 📜 単語リストを用いないバイアス除去の必要性 単語の情報を実ベクトルに表現する単語分散表現は様々な自然言語処理のタスクで活用されている．しかし，有益な情報と共に差別的なバイアスも学習されている．例えば，$\\overrightarrow{nurse}$は$\\overrightarrow{he}$より$\\overrightarrow{she}$と類似度が高く，$\\overrightarrow{doctor}$は$\\overrightarrow{she}$より$\\overrightarrow{he}$と類似度が高くなると言った性差別的な類似性の偏りなどが知られている．このようなバイアスを単語分散表現から除去するために様々なバイアス除去手法が提案されている．一方で，これらの手法はバイアス除去を学習するためにバイアス単語のリストが必要になる．例えば，性差別のバイアスであればsheやheなど，宗教差別のバイアスであればchristianやmuslimなどで構成される単語リストが必要となる．一方で，差別があってはいけないバイアスを全てリストアップし，そのバイアスに対して十分な量の単語リストを作成することはコストや網羅性の観点から現実的ではない． バイアスに関連する単語リストを用いずにバイアス除去するために，本研究では辞書の定義文と関連がない情報を単語分散表現から除去することでバイアスを除去する手法を提案する．辞書の定義文は人間により客観的な単語の意味が記述されており，バイアスが含まれていないと仮定できる．定義文と関係する情報を保持し，無関係な情報を除去することで様々なバイアスを除去できることを示す． 🛠 辞書を用いた単語分散表現のバイアス除去 提案手法は3つの損失関数から構成されている．損失関数について説明するためにまずEncoderを定義する．単語$w$に対する単語ベクトルを$\\boldsymbol{w}$とする．$\\boldsymbol{w}$が入力として与えられたEncoderを$E(\\boldsymbol{w};\\boldsymbol{\\theta}_e)$とする．ここで，$\\boldsymbol{\\theta}_e$はEncoderのパラメータである．そして，$E(\\boldsymbol{w};\\boldsymbol{\\theta}_e)$をバイアス除去された単語分散表現として最終的に使う．この時，3つの損失関数はそれぞれ以下のように定義される： 1つ目は，定義文と関係する情報を学習する損失関数である． $$ J_{d}(w) = ||\\boldsymbol{s}(w) - D_d(E(\\boldsymbol{w}; \\boldsymbol{\\theta}_e); \\boldsymbol{\\theta}_d)||^2_2 $$ ここで，$\\boldsymbol{s}(w)$は$w$に関する定義文ベクトルである．文に含まれる単語の単語ベクトルから文ベクトルを計算する手法はいくつか提案されている．ここではSmoothed Inverse Frequency (SIF) を用いて定義文ベクトルを計算する．SIFはコーパス内の単語の出現確率の逆数で単語ベクトルを加重平均することで文ベクトルを計算する．この損失関数は中間層から$\\boldsymbol{s}(w)$予測することで$E(\\boldsymbol{w};\\boldsymbol{\\theta}_e)$が$\\boldsymbol{w}$から$w$の定義文に関連する情報を保持することを目的としている． 2つ目は，定義文と関係しない情報を単語ベクトルから除去する損失関数である． $$ \\begin{align} J_{a}(w) &amp;= (E(\\phi(\\boldsymbol{w}, \\boldsymbol{s}(w)); \\boldsymbol{\\theta}_e)^{\\top} E(\\boldsymbol{w}; \\boldsymbol{\\theta}_e))^2 \\\\ \\phi(\\boldsymbol{w}, \\boldsymbol{s}(w)) &amp;= \\boldsymbol{w} - \\boldsymbol{w}^{\\top}\\boldsymbol{s}(w) \\frac{\\boldsymbol{s}(w)}{||\\boldsymbol{s}(w)||} \\end{align} $$ ここで$\\phi(\\boldsymbol{w}, \\boldsymbol{s}(w))$は，$\\boldsymbol{w}$と$\\boldsymbol{w}$の$\\boldsymbol{s}(w)$方向への射影を用いた減算によりベクトルを計算する．このベクトルは$\\boldsymbol{w}$に表現されている$\\boldsymbol{s}(w)$とは無関係な情報を表している．そして，$\\phi(\\boldsymbol{w}, \\boldsymbol{s}(w))$と$\\boldsymbol{w}$をそれぞれ入力として与えられた中間層の内積を最小化することは定義文ベクトルと無関係な情報を除去することを意味している．これにより，差別的バイアス（定義文とは無関係な情報）の除去を行う． 3つ目は，$\\boldsymbol{w}$の情報を中間層に学習するための損失関数である．これはAutoencoderの二乗誤差と同様の働きをする． $$ J_{c}(w) = ||\\boldsymbol{w} - D_c(E(\\boldsymbol{w}; \\boldsymbol{\\theta}_e); \\boldsymbol{\\theta}_c)||^2_2 $$ そして，これらの損失関数を重み付き和で合計することで最終的な損失関数$J(w)$を定義する： $$ J(w) = \\alpha J_c(w) + \\beta J_d(w) + \\gamma J_a(w) $$ 📊 バイアス評価とバイアスの可視化 Word2vec, GloVeとfastTextに対して提案手法を適応した．評価データとしてはWord Embedding Association Test (WEAT) とWord Association Test (WAT) を用いる．WEATは性別や人種など単語分散表現の様々なバイアスを評価することができる．WATは性別に関するバイアスを評価することが可能である．WEATとWATはスコアの値が0から離れているほどバイアスがあることを示している．以下の表はオリジナルの単語分散表現 (Org) とバイアス除去した単語分散表現 (Deb) の結果を示している．この結果から，提案手法は単語リストを用いずにさまざまなバイアスを除去できていることがわかる．そして，特にWord2VecとFastTextにおいて効果的にバイアス除去されている． 最後に，Word2vecのバイアス除去前後の単語ベクトルを可視化することで，様々なバイアスを除去できているか調べる．以下の図は，職業単語のベクトルと性別：$\\overrightarrow{he} - \\overrightarrow{she}$，人種：$\\overrightarrow{caucasoid} - \\overrightarrow{negroid}$と年齢：$\\overrightarrow{elder} - \\overrightarrow{youth}$により計算された属性ベクトルとの類似度を示している．各属性ベクトルとの類似度が小さいほど，職業単語が各属性の情報を保持していないことを示しており，バイアスがないことを意味する．この図からバイアス除去することで全体的に0付近に単語が分布するようになっていることがわかる．特に，年齢に関連する単語で顕著な傾向が見られる．","link":"/2021/04/20/research_debias_with_dictionary/"},{"title":"論文メモ：多言語音声言語モデルmSLAM、ニューラルネットワークの忘却は必要、事前学習モデルを効率化するpNLP-Mixer","text":"💡 概要 51言語の音声データと101言語のテキストデータで学習された多言語音声言語モデルmSLAM ニューラルネットワークの忘却、実は性能改善に寄与している 射影ベースのMLP-Mixerにより事前学習モデルを効率化するpNLP-Mixer 51言語の音声データと101言語のテキストデータで学習された多言語音声言語モデルmSLAM タイトル： mSLAM: Massively multilingual joint pre-training for speech and text 著者：Ankur Bapna, Colin Cherry, Yu Zhang, Ye Jia, Melvin Johnson, Yong Cheng, Simran Khanuja, Jason Riesa, Alexis Conneau 会議・出版： arXiv 年： 2022 multilingual Speech and LAnguage Model (mSLAM) は多言語のラベル付けされていない大量の音声データとテキストデータに対して事前学習を行い、音声とテキストの表現を学習する多言語音声言語モデルである。mSLAMは、51言語のラベル無し音声をw2v-BERTで、101言語の文字レベルテキストをSpanBERTで学習させたモデルである。また、これらのラベル無しデータに加え、音声表現とテキスト表現の共有を促進するために少量の音声とテキストのパラレルデータに対してもmSLAMを学習させる。 mSLAMをいくつかの音声理解タスクで評価し、テキストと音声の両方を考慮した事前学習が音声のみの事前学習と比較して、音声翻訳、発話意図分類、音声言語IDの性能を向上させ多言語ASRで高い性能であることを明らかにした。また、mSLAMは音声とテキストの両方でfine-tuningを行うことができfine-tuningにおいてテキストのパラレルデータを直接利用することで、音声翻訳の品質をさらに向上させることができる。また、XNLI文対分類において大量のパラレルデータを持つ（ヨーロッパ）言語ではmSLAMの半分のサイズのテキストのみのモデルと同等のゼロショット性能を達成した。一方で、パラレルデータの少ない言語では深刻な品質劣化を示した。 ニューラルネットワークの忘却、実は性能改善に寄与している タイトル：Fortuitous Forgetting in Connectionist Networks 著者：Hattie Zhou, Ankit Vani, Hugo Larochelle, Aaron Courville 会議・出版： ICLR 年： 2022 忘却は人間や機械学習の両方においてあまり好ましくない性質と見なされている。例えば、ニューラルネットワークにおいて破壊的忘却はよく知られた忘却に関する問題である。 しかし、この論文では忘却はむしろ機械学習にとって好ましいものであることを示す。ニューラルネットワークの学習過程の枠組みとして「忘却と再学習」を紹介する。忘却ステップではモデルから望ましくない情報を選択的に除去し、再学習ステップでは異なる条件において一貫して有用な情報を強化する。 「忘却と再学習」の枠組みは、画像や言語の多くの既存のiterative学習アルゴリズムを統合し、望ましくない情報の忘却という観点から、これらのアルゴリズムの成功を理解することを可能にする。これらの結果を元により適切な忘却機構を設計することで、既存のアルゴリズムを改善することができる。 射影ベースのMLP-Mixerにより事前学習モデルを効率化するpNLP-Mixer タイトル：pNLP-Mixer: an Efficient all-MLP Architecture for Language 著者：Francesco Fusco, Damian Pascual, Peter Staar 会議・出版： arXiv 年： 2022 大規模な事前学習済み言語モデルは、自然言語処理様々なタスクの状況を一変させた。限られた数のアノテーションしか存在しないタスクでも高い性能を実現できるが、推論において計算コストに関して依然として課題がある。これらを解決するために主に２つの方法が知られている。1つ目はpruning、量子化やmixed precisionなどと組み合わせて高度に最適化されたハードウェアを用いて高速化する方法である。2つ目は、大規模モデルをよりパラメータ数が少ないモデル（例：RNN）に置き換えることで高速化する方法です。 本論文では、射影ベースのMLP-Mixerを用いたpNLP-Mixerによって重み効率を改善する。これはより効率的なモデルに置換する2つ目の手法に属する。MLP-MixerはRNNなどと違い並列化でき、Transformerと違い計算量は文長の線形に依存するだけであり長距離の依存構造も考慮することができる。 pNLP-Mixerを2つの多言語意味解析データセットで評価した。その結果、pNLP-Mixerは38倍のパラメータを持つmBERTとほぼ同等の性能を示し、3倍少ないパラメータで最先端の効率的なモデル（pQRNN）を上回る性能を示しました。","link":"/2022/02/11/research_2022_02_11/"},{"title":"マスク付き言語モデルのマスクトークンを用いない差別的バイアスの評価","text":"タイトル：Unmasking the Mask – Evaluating Social Biases in Masked Language Models 著者：Masahiro Kaneko, Danushka Bollegala 会議・出版：arXiv 年：2021 💡 概要 BERTやALBERTのようなマスク付き言語モデルの公平性に関するバイアス評価についての研究 マスクトークンを用いないバイアス評価手法 (AULとAULA)を提案 バイアス評価にマスクトークンを用いることの問題点を分析 📜 MLMのバイアス評価 BERTやALBERTのようなマスク付き言語モデル（Masked Language Models; MLMs）には差別的なバイアスが学習されていることが知られている．例えば，ステレオタイプ文 “Black people are too poor to drive good cars” と非ステレオタイプ文 “White people are too poor to drive good cars” という文対[1]が与えられた際に，MLMはステレオタイプ文により高い尤度を与えてしまう問題などがある．既存手法はマスクトークンを用いて各文に対して尤度を計算し，それらの尤度の偏りによりMLMのこのようなバイアスを評価している．本研究ではバイアス評価でマスクトークンを用いることの問題点を示し，マスクトークンを使わずにMLMのバイアスを評価する All Unmasked Likelihood (AUL) と AUL with Attention weights (AULA)を提案している． マスクトークンを用いてバイアス評価する手法の問題点 本研究では “[MASK] people are too poor to drive good cars” や “Black/White people are too [MASK] to drive good cars” のように文中のトークンをマスクし，その予測を用いてバイアス評価する手法の問題点を3つあげている．これらの問題点は分析で詳しく調査している． マスクされたトークンの予測精度は低く，そのようなMLMの確信度が低い予測を用いて評価することはバイアス評価の信頼性が低くなると考えられる．例えば，上記の例のようにマスクされた箇所で複数の単語が成立するような場合に特に精度が低くなる． MLMを下流タスクで用いる際は，多くの場合マスクトークンを用いない．そのため，マスクトークンを用いた評価は実際のMLMの利用方法と乖離した状況でバイアス評価していることとなる． マスクトークンはバイアスに対して中性であると考えられているが，マスクトークン自体がトークン頻度の影響によるバイアスを含んでいる．そのため，そのようなマスクトークンのバイアスが評価にノイズになっていると考えられる． 🛠 マスクを用いないMLMのバイアス評価 上記のマスクトークンに関する問題を解決するためにマスクトークンを用いないバイアス評価手法AULとAULAを提案する． AUL 入力文を$S = w_0, w_1, … , w_{|S|}$と定義する．ここで$w$は文中のトークンであり，$|S|$は文長である．その時，事前学習されたパラメータ$\\theta$を持つMLMに対するAULは以下の式で計算される： $$ {\\rm AUL}(S) := \\frac{1}{|S|} \\sum_{i=1}^{|S|} \\log P_{\\rm MLM}(w_i|S;\\theta) $$ この式は入力文$S$をMLMにそのまま与え，その各トークンに対するMLMの予測の平均を計算する． AULA AULでは全てのトークンの予測を等しく考慮しているが，文中のトークンの重要度は異なる．例えば，名詞や動詞などはバイアス評価でより重要になると考えられる．そこで，文中のトークンの重要度も考慮してバイアス評価するためにMLMのアテンション重みで重み付けする． $$ {\\rm AULA}(S) := \\frac{1}{|S|} \\sum_{i=1}^{|S|} \\alpha_i \\log P_{\\rm MLM}(w_i|S;\\theta) $$ ここで$\\alpha_i$は$w_i$に対する全multi-headアテンションの重みを平均して計算している． バイアススコア ステレオタイプ文は$S^{\\rm st}$とし，非ステレオタイプ文は$S^{\\rm at}$と表記する．そして，テストデータの$N$個の事例に対して，$f \\in {AUL, AULA}$としてバイアススコアを以下の式で計算する： $$ \\frac{1}{N} \\sum_{(S^{\\rm st}, S^{\\rm at})} \\mathbb{I}(f(S^{\\rm st}) &gt; f(S^{\\rm at})) $$ $\\mathbb{I}$は指示関数で，条件が満たされていれば1，満たされていなければ0を返す．このバイアススコアは50であればステレオタイプ文と非ステレオタイプ文どちらにも偏っていない，つまりこのデータセット内ではMLMが公平であることを示す．50以上であればステレオタイプにより高い尤度を与えるバイアスがあることを示す．50以下であれば非ステレオタイプ文により高い尤度を与えるバイアスがあることを示す． 📊 実験結果 バイアス評価 まず，バイアス評価の結果について調査する．CrowS-Pairs (CP) と StereoSet (SS) はそれぞれバイアス評価のデータセットである．CPスコア (CPS) とSSスコア (SSS) は各データセットの研究で提案されたマスクを用いてバイアス評価する既存手法である． この表ではCPSとSSSはそれぞれCPとSSで評価している．実験の結果から全ての評価手法でBERT, RoBERTaとALBERTはバイアスを学習しているという結果が示されている．そして，マスクを用いたバイアス評価手法はマスクを用いない提案手法と比較してバイアスを過大評価する傾向があることがわかる． メタ評価 次に，提案したバイアス評価手法が既存の評価手法より良いことを示す．そのために，評価の評価であるメタ評価を行う．データセットには人手のバイアススコアが付与されておりこれを使いバイアス評価と人手バイアススコアの傾向を比較する．人手スコアはバイアスが多いか少ないかの2値でバイアススコアは連続値であるため，スピアマンやピアソンなどの順位相関はここでは適していない．そのため，バイアススコアと人手バイアススコアを使ったROC曲線とAUCを用いてメタ評価を行う．以下の図はBERTに対するバイアス評価のROC曲線とAUCを表している．ここで各手法は人手バイアススコアに最適化されているわけではないので，AUCが50以下になることがある．この図からAULとAULAが既存の評価手法より優れていることがわかる． 🔬 分析 マスクされたトークンの予測精度 マスクされたトークンの予測精度を調べることで，マスクを用いたバイアス評価が確信度の低い予測を用いていることを示している．以下の表は各手法のトークンの予測性能を示している．AULはマスクトークンを用いないため，マスクせず入力トークンが与えられた際の精度を示している． 以下の表から既存手法はマスクされたトークンの予測精度が低いことと，提案手法は高い精度を達成できていることがわかる．提案手法は入力文をそのまま予測しているので精度は100%になるように考えられるが，そうはなっていない．これはMLMは内部で情報の取捨選択をしているからではないかと考えらる． マスクトークンのバイアス 次に，マスクトークンに含まれるバイアスを調べる．マスクトークンだけのバイアススコアへの影響を分析するために，入力文を全てマスクした時の尤度の偏りを評価する．高頻度なトークンほどマスクすることになるため，学習データに高頻度で出現する多数派に関するトークンと低頻度で出現する少数派に関するトークンでマスクした時の尤度が偏ると考えられる．そこで，男性や米国におけるキリスト教徒などadvantageグループ（Adv）と女性や米国におけるイスラム教徒などのdisadvantageグループ (Dis) に関するステレオタイプ文ごとにバイアススコアを調査する． 以下の表は全ての入力をマスクした時のバイアス評価の結果を示している．参考のためにAULとAULAのバイアススコアも示してある．この結果から，Advに関するステレオタイプに高い尤度を与えるようなバイアスがマスクトークンに学習されていることがわかる．一方で，Disに関するステレオタイプは低い尤度を与える傾向がある．このことからマスクトークンはAdvのステレオタイプを過大評価し，Disのステレオタイプを過小評価するバイアスが学習されていると言える． 入力文がマスクされていない時，MLMは入力文の妥当性を評価しているか？ 直感的に入力文をそのまま予測することは簡単なタスクであり，全ての入力文に高い尤度を与えることが可能なため，適切に入力文の情報を尤度に反映できないのではという疑問が生じると考えられる．そこで，マスクせず入力文をMLMに与えたときの予測が妥当性を反映しているかどうかを調査する．ここでは入力文に2種類のノイズを与えそのときの精度を評価する．1つ目のノイズは入力文のトークンの語順をシャッフルすることで作成する（Shuffledの例：All people from morocco are thieves → people morocco All from thieves are）．2個目のノイズは入力文の1単語を無関係な単語に置換することで作成する（Unrelatedの例：All people from morocco are thieves → All people from morocco are pizza）．置換ノイズはSSデータセットに言語モデルの性能を評価するために付与されており，それをそのまま用いる．提案手法が入力文の情報を反映している場合ノイズを含む文では性能が低下する．一方で，反映していない場合はノイズの有無に関わらず常に高い精度となる． 以下は，CPとSSデータセットそれぞれでノイズを与えた時の精度を示している．括弧内はノイズなしのときとの精度差を表している．ノイズがある文を与えられると適切に精度が低下することからマスクせずにMLMに入力文を与えた場合でも，そこから計算される尤度は入力文の情報を反映していることがわかる． これはCrowS-Pairsに含まれる文対を例として提示している． ↩︎","link":"/2021/04/16/research_evaluate_bias_in_mlm/"},{"title":"英語の文法誤り訂正に入門しつつFairseqでモデルを学習・推論して評価する","text":"💡 概要 評価・推論するための英語文法誤り訂正について最低限の知識が得られる Fairseqを用いてTransformerの文法誤り訂正モデルを動かす 文法誤り訂正モデルの推論結果を評価する はじめに 2021年12月現在，著者の金子は東工大岡崎研で研究員をしている．学生の頃に文法誤り訂正 (Grammatical Error Correction; GEC) に関する研究をやっていた関係で，研究室の学生と一緒にGECの研究をやっている（現在2人の学生がGECを研究中！）．その際，これを見ておけばGECモデルを最低限動かせるようになるというようなものがあれば良いなと思ったので，研究室に配属されてGECの研究を始めようとしている学生がお手軽に国際会議に投稿されているような設定でGECモデルを動かせるようになってくれれば嬉しいという記事を書く． コードは全てのこのリポジトリにあるのでそれを使う． GECデータセットの準備 学習データと開発データについて 一般的にBEA shared taskで用いられたデータセットが学習データと開発データとして広く使われている．このデータセットではFCE, Lang-8, NUCLEとW&amp;I + LOCNESSの4つのデータセットの学習データをくっつけることで，BEA学習データを構築する．その他の学習データとして，Wikipediaの編集履歴から作成したWikEd（現在は配布されていない気がする），訂正が低品質であるが大規模な学習者データであるEFCamDatや論文ドメインのAESWなどが存在する．そして，W&amp;I+LOCNESSの開発データがチューニングのために使われることが多い．このブログではBEA学習データとW&amp;I+LOCNESS開発データを用いる． まずBEA shared taskのサイトの「Other Corpora and Download Links」からデータセットをゲットする（Lang-8とNUCLEはリクエストが必要）．M2形式(誤文に対する編集が1行ずつに書かれている)でデータが提供されているためfairseqで学習するためにはパラレルデータ形式（ソース文とターゲット文別々のテキストデータに1行ずつ並んだ形式）に変換する必要がある．そして，学習データでは基本的に訂正されていない文対は前処理で学習データから除外することが多い． 評価データと評価指標について 主に評価データとしては，学習者のエッセイをベースにしたW&amp;I+LOCNESS，CoNLL-2014とJFLEG [記事]が使われている．W&amp;I+LOCNESSは学習者の習熟度に関する情報が付与されている．W&amp;I+LOCNESSやCoNLL2014と異なりJFLEGは最低限の文法的な訂正だけでなく，流暢になるように訂正が行われている．その他の評価データとしてウェブドメインのGMEGやCWEBなどがある．このブログではを用いるW&amp;I+LOCNESS評価データ，CoNLL-2014とJFLEGを用いる． GECでは評価データによって使われる評価指標が異なる．CoNLL-2014，W&amp;I+LOCNESSとJFLEGではそれぞれ以下の評価指標が使われている． ${\\rm M}^2$, CoNLL-2014：ターゲット文と出力文に対するスパンの一致に対して適合率, 再現率と${\\rm F}_{0.5}$値（適合率をより重視する）で評価を行う． ERRANT, W&amp;I+LOCNESS：${\\rm M}^2$と同じように適合率, 再現率と${\\rm F}_{0.5}$で評価を行う．置換，削除や挿入のような編集タイプや前置詞誤りや動詞誤りのような誤りタイプごとのスコアなども評価することができる．スパンの計算方法の違いから${\\rm M}^2$はERRANTと比較してシステムを過大評価する傾向にある． GLEU, JFLEG：ソース文，ターゲット文と出力文に対してn-gramの一致率を用いて評価する．BLEU（機械翻訳の評価手法）を参考にしている． その他に参照文を必要としない提案手法としてSOMEなどもある． データセット構築のコード W&amp;I+LOCNESSとFCEはwgetによりダウンロードすることが可能である．Lang-8とNUCLEはリクエストが必要であるため，各自申請してdata/m2に配置する．これらのデータはM2形式で配布されており，Fairseqで取り扱えるようにパラレル形式に変換する必要がある． 123456789# W&amp;I+LOCNESSとFCEデータをダウンロードし`data/m2`ディレクトリに配置する．Lang-8とNUCLEは適宜リクエストして配置する．M2_DIR=data/m2PARA_DIR=data/parallelmkdir -p $M2_DIRmkdir -p $PARA_DIRwget https://www.cl.cam.ac.uk/research/nl/bea2019st/data/fce_v2.1.bea19.tar.gz -O - | tar xvf - -C $M2_DIRwget https://www.cl.cam.ac.uk/research/nl/bea2019st/data/wi+locness_v2.1.bea19.tar.gz -O - | tar xvf - -C $M2_DIR# データに対して前処理（1：M2形式からパラレルデータ形式に変換する，2：データを結合する，3：訂正されていない文対を除外する）を行う．./script/preprocess.sh $M2_DIR $PARA_DIR 上記のコマンドによりW&amp;I+LOCNESSの評価データはダウンロードされているが，CoNLL-2014とJFLEGは以下のコマンドでdataにダウンロードする必要がある． 12345# CoNLL-2014のダウンロードとパラレルデータ形式に変換wget https://www.comp.nus.edu.sg/~nlp/conll14st/conll14st-test-data.tar.gz -O - | tar xvf - -C datapython src/convert_m2_to_parallel.py data/conll14st-test-data/noalt/official-2014.combined.m2 data/conll14st-test-data/noalt/conll2014.src data/conll14st-test-data/noalt/conll2014.trg# JFLEGのダウンロードgit clone https://github.com/keisks/jfleg.git data/jfleg FairseqでGECモデルを学習する train.shを使い作成したデータをバイナリーデータにしGECモデルを学習する．ここではGECモデルとしてTransformer-bigを使用する． train.sh12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576eed=1111num_operations=8000subword_model=model/bpe.modelcpu_num=`grep -c ^processor /proc/cpuinfo`FAIRSEQ_DIR=fairseq/fairseq_cliDATA_DIR=data/parallelPROCESSED_DIR=process/$seedMODEL_DIR=model/$seedmkdir -p $PROCESSED_DIR# Fairseqに読み込ませるためのバイナリーデータを作成する．if [ -e $PROCESSED_DIR/bin ]; then echo 既にバイナリーデータは存在している．else echo バイナリデータを作成する． mkdir -p $PROCESSED_DIR/bin subword-nmt learn-bpe -s $num_operations &lt; $DATA_DIR/train_corrected.trg \\ &gt; $PROCESSED_DIR/trg_$num_operations.bpe subword-nmt apply-bpe -c $PROCESSED_DIR/trg_$num_operations.bpe \\ &lt; $DATA_DIR/train_corrected.src \\ &gt; $PROCESSED_DIR/train.src subword-nmt apply-bpe -c $PROCESSED_DIR/trg_$num_operations.bpe \\ &lt; $DATA_DIR/train_corrected.trg \\ &gt; $PROCESSED_DIR/train.trg subword-nmt apply-bpe -c $PROCESSED_DIR/trg_$num_operations.bpe \\ &lt; $DATA_DIR/dev.src \\ &gt; $PROCESSED_DIR/dev.src subword-nmt apply-bpe -c $PROCESSED_DIR/trg_$num_operations.bpe \\ &lt; $DATA_DIR/dev.trg \\ &gt; $PROCESSED_DIR/dev.trg python -u $FAIRSEQ_DIR/preprocess.py \\ --source-lang src \\ --target-lang trg \\ --trainpref $PROCESSED_DIR/train \\ --validpref $PROCESSED_DIR/dev \\ --testpref $PROCESSED_DIR/dev \\ --destdir $PROCESSED_DIR/bin \\ --workers $cpu_num \\ --joined-dictionary \\ --tokenizer spacefi# GECモデルの学習mkdir -p $MODEL_DIRpython -u $FAIRSEQ_DIR/train.py $PROCESSED_DIR/bin \\ --save-dir $MODEL_DIR \\ --source-lang src \\ --target-lang trg \\ --log-format simple \\ --fp16 \\ --max-epoch 30 \\ --arch transformer_vaswani_wmt_en_de_big \\ --max-tokens 4096 \\ --optimizer adam \\ --adam-betas '(0.9, 0.98)' \\ --lr 0.0005 \\ --lr-scheduler inverse_sqrt \\ --warmup-updates 4000 \\ --warmup-init-lr 1e-07 \\ --stop-min-lr 1e-09 \\ --dropout 0.3 \\ --clip-norm 1.0 \\ --weight-decay 0.0 \\ --criterion label_smoothed_cross_entropy \\ --label-smoothing 0.1 \\ --num-workers $cpu_num \\ --no-epoch-checkpoints \\ --share-all-embeddings \\ --seed $seed FairseqでGECモデルを推論し評価する 推論結果を評価するために評価指標を3つevalディレクトリに配置する．W&amp;I+LOCNESSはCodaLabで評価するためERRANTは直接使わない． 1234567mkdir eval# M2のダウンロードgit clone https://github.com/kanekomasahiro/m2_python3.git eval/m2_python3# GLEUのダウンロードgit clone https://github.com/kanekomasahiro/gec-ranking_python3.git eval/gec-ranking_python3# 使わないが一応ERRANTのダウンロードgit clone https://github.com/chrisjbryant/errant.git eval/errant interactive.shを使い学習したモデルで評価データに対して推論を行う．wi，conllまたはjflegのどれを推論するか引数で指定する．そして，CoNLL-2014（評価に時間がかかることがある）とJFLEGに対しては推論結果の評価も行われる．評価結果や出力結果はoutput/$seedに保存される． interactive.sh123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475seed=1111num_operations=8000beam=5test_data=$1 # wi conll jflegFAIRSEQ_DIR=fairseq/fairseq_cliDATA_DIR=dataPROCESSED_DIR=processMODEL_DIR=model/$seedOUTPUT_DIR=outputEVAL_DIR=evalexport PYTHONPATH=$FAIRSEQ_DIRmkdir -p $OUTPUT_DIR/$seedif [ -e $PROCESSED_DIR/$seed/${test_data}_bin ]; then echo $test_data のバイナリーデータは既に存在する．else echo $test_data のバイナリーデータを作成する． cpu_num=`grep -c ^processor /proc/cpuinfo` if [ $test_data = 'wi' ]; then subword-nmt apply-bpe -c $PROCESSED_DIR/$seed/trg_$num_operations.bpe \\ &lt; $DATA_DIR/wi.test.src \\ &gt; $PROCESSED_DIR/$seed/$test_data.src elif [ $test_data = 'conll' ]; then subword-nmt apply-bpe -c $PROCESSED_DIR/$seed/trg_$num_operations.bpe \\ &lt; $DATA_DIR/conll14st-test-data/noalt/conll2014.src \\ &gt; $PROCESSED_DIR/$seed/$test_data.src elif [ $test_data = 'jfleg' ]; then subword-nmt apply-bpe -c $PROCESSED_DIR/$seed/trg_$num_operations.bpe \\ &lt; $DATA_DIR/jfleg/test/test.src \\ &gt; $PROCESSED_DIR/$seed/$test_data.src fi cp $PROCESSED_DIR/$seed/$test_data.src $PROCESSED_DIR/$seed/$test_data.trg python -u $FAIRSEQ_DIR/preprocess.py \\ --source-lang src \\ --target-lang trg \\ --trainpref $PROCESSED_DIR/$seed/train \\ --validpref $PROCESSED_DIR/$seed/$test_data \\ --testpref $PROCESSED_DIR/$seed/$test_data \\ --destdir $PROCESSED_DIR/$seed/${test_data}_bin \\ --srcdict $PROCESSED_DIR/$seed/bin/dict.src.txt \\ --tgtdict $PROCESSED_DIR/$seed/bin/dict.trg.txt \\ --workers $cpu_num \\ --tokenizer spacefi# GECモデルを用いて評価データの推論python -u $FAIRSEQ_DIR/interactive.py $PROCESSED_DIR/$seed/bin \\ --source-lang src \\ --target-lang trg \\ --path $MODEL_DIR/checkpoint_best.pt \\ --beam $beam \\ --nbest $beam \\ --no-progress-bar \\ --buffer-size 1024 \\ --batch-size 32 \\ --log-format simple \\ --remove-bpe \\ &lt; $PROCESSED_DIR/$seed/$test_data.src &gt; $OUTPUT_DIR/$seed/$test_data.nbest.tok# n-bestから1-bestを抽出するcat $OUTPUT_DIR/$seed/$test_data.nbest.tok | grep &quot;^H&quot; | python -c &quot;import sys; x = sys.stdin.readlines(); x = ' '.join([ x[i] for i in range(len(x)) if (i % ${beam} == 0) ]); print(x)&quot; | cut -f3 &gt; $OUTPUT_DIR/$seed/$test_data.best.toksed -i '$d' $OUTPUT_DIR/$seed/$test_data.best.tok# 推論結果を評価するif [ $test_data = 'conll' ]; then CONLL_DIR=data/conll14st-test-data/noalt/ $EVAL_DIR/m2_python3/m2scorer $OUTPUT_DIR/$seed/$test_data.best.tok $CONLL_DIR/official-2014.combined.m2 &gt; $OUTPUT_DIR/$seed/$test_data.evalelif [ $test_data = 'jfleg' ]; then JFLEG_DIR=data/jfleg/test $EVAL_DIR/gec-ranking_python3/scripts/compute_gleu -s $JFLEG_DIR/test.src -r $JFLEG_DIR/test.ref0 $JFLEG_DIR/test.ref1 $JFLEG_DIR/test.ref2 $JFLEG_DIR/test.ref3 -o $OUTPUT_DIR/$seed/$test_data.best.tok -n 4 &gt; $OUTPUT_DIR/$seed/$test_data.evalfi W&amp;I+LOCNESSは評価データのターゲット側が公開されていないため，CodaLabにGECモデルの推論結果を投稿する必要がある．アカウントを作成し，zipコマンドにより推論結果を圧縮しParticipateのSubmitを押してアップロードすることでERRANTスコアを取得できる． seedによって1.5ぐらい前後するがスコアとしてはW&amp;I+LOCNESS: 50, CoNLL-2014: 49, JFLEG: 53がでる． おわり これはGEC (Grammatical Error Correction) Advent Calendar 2021のための記事である．需要があれば疑似データ生成モデルの動かし方についても説明するかもしれない．","link":"/2021/12/17/research_gec_tutorial/"},{"title":"プロンプトを用いた言語モデルのFew-shot学習は過大評価されている","text":"タイトル： True Few-Shot Learning with Language Models 著者： Ethan Perez, Douwe Kiela, Kyunghyun Cho 会議・出版： NeurIPS 年： 2021 💡 概要 大規模データで事前学習された言語モデルを用いて少数の例のみを用いた学習が注目されている 一方で，既存研究ではモデルの選択時に大規模データを使っていたり不明瞭だったりと問題があるため，cross-validationとminimum description lengthを用いてTrue few-shot learning設定で有効であるかどうかを検証した True few-shot学習の設定だとモデル選択はかなり困難であることを明らかにし，先行研究では言語モデルのfew-shot学習を大幅に過大評価していることを問題提起している 📜 言語モデルのfew-shot学習 大規模データで事前学習された言語モデルに対してプロンプトを用いたfew-shot学習が注目されている．以下の図（GPT-3の論文より）で示されているように，言語モデルのfew-shot学習では，タスクの説明，例と言語モデルから答えを引き出すプロンプトを用いてタスクを解く．従来のラベル付きデータから教師あり学習をするfine-tuningと違いfew-shot学習では言語モデルのパラメータを更新しない．教師あり学習はデータを豊富にある場合に性能が高い反面，ラベル付きデータを作成するにはコストがかかる．この課題を克服できる可能性があるため言語モデルのfew-shot学習は有望である． 😞 既存のfew-shot学習の問題とその分類 既存の言語モデルでは，学習には小規模な事例を用いているが一方で開発データでは大規模なデータセットを用いたり，他のタスクの開発データを用いられていたりする．このような設定では開発データとして用いた大規模なラベル付きデータを学習データとして用いることができてしまう．つまり，既存のfew-shot学習では多くのラベル付きデータに依存しており，これはfew-shot学習の基準を満たしていないと考えられる．この論文ではこのようなfew-shot学習をTuned few-shot学習と呼ぶ． この論文では，Tuned few-shot学習に対して大規模な開発データを用いず小規模な学習データと開発データを用いるTrue few-shot学習と呼ぶ．そして，既存のTuned few-shot学習で有効な手法がTrue few-shot学習の設定において有効であるかを調査する． 🛠 True few-shot学習におけるチューニング True few-shot学習において既存手法が有効であるかどうかを検証する方法について説明する前に，まずfew-shot学習におけるチューニングについて定義する．全てのデータ$D$からサンプルされた学習データ$T \\sim D$を用いて学習した後に，開発データ$V \\sim D$における汎化誤差$L$を最小化するアルゴリズム（テンプレートの作成方法やいくつ使うかなど）$A^* \\in A_1, …, A_a$により決定する，ここで$A(T, R)$は$T$と学習に影響を与えるさまざまなランダム要素$R$（初期化や学習の順番など）をラベル予測する関数にマップする．このとき汎化誤差$L(A(T, R); V)$は開発データ$V$で計算される． この論文では，交差検証と最小記述長によりプロンプトを用いた言語モデルのTrue few-shot学習の設定で検証する． 交差検証 交差検証ではランダムに$T$を$K$個の等しいサイズのデータ$F(T)^1, …, F(T)^K$に分割する．そして，学習に用いたデータ$F(T)^{\\lnot k}$の残りを開発データ$F(T)^k$とし，$F(T)^k$における損失の平均を評価することでチューニングする，式で表すと以下のようになる： $$ CV(A, R, F) = \\mathbb{E}_{k \\sim {\\rm Unif}(1, K)} [L(A(F(T)^{\\lnot k},R); F(T)^k)] $$ 最小記述長 最小記述長では$k$番目までのデータを学習に用いて，$k$番目のデータを開発データとし損失の平均で評価を行う．式で表すと以下のようになる： $$ MDL(A, R, F) = \\mathbb{E}_{k \\sim {\\rm Unif}(1, K)} [L(A(F(T)^{1:k-1},R); F(T)^k)] $$ 📊 実験結果 まず，事前学習された言語モデルの事実や常識を評価するデータセットであるLAnguage Model Analysis (LAMA)を用いてGPTのTrue few-shot学習設定の性能を評価する．交差検証と最小記述長を用いてプロンプトの作成方法（人手での作成やWikipediaからの抽出など）をチューニングする． 上記の左図はLAMAにおけるGPTの性能を表している．縦軸が性能であり，横軸がGPTのモデルサイズである．Worstは最も性能が悪いプロンプトの結果，Meanはランダムにプロンプトを選択した結果，MDLは最小記述長を用いた結果，CVは交差検証を用いた結果，Bestは大規模な検証データを用いるTuned few-shotの結果である．そして，右図はMDLとCVそれぞれのMeanからのBestと比較した改善割合を示している．0%はMeanから改善なしで100%がBestと同等の改善を意味している．これらの結果から，True few-shot学習の設定ではBestと比較してほとんど改善していない，ランダムにプロンプトを選択した時と同程度であることがわかる．これはTrue few-shot学習の設定では適切なプロンプトを選択することが難しいといえる．そして，既存研究では言語モデルにおけるfew-shot学習は過大評価されていると考えられる． 📍 few-shot学習の今後について このような既存の言語モデルにおけるfew-shot学習の問題を解決するために，最後に以下のようなことをお勧めしている： 全てのハイパーパラメータを報告する 学習データと開発データ両方のデータサイズを報告する 既存研究のハイパラをそのまま使わずに，小規模な開発データで自分でチューニングしたハイパーパラメータを用いる．","link":"/2021/12/05/research_true_few_shot/"},{"title":"名古屋地区NLPセミナーでの公平性に関する発表のスライド","text":"第62回名古屋地区NLPセミナー において，「事前学習された分散表現における公平性」というタイトルで金子が発表した資料です．","link":"/2021/11/30/research_nagoyanlpseminar/"},{"title":"流暢な文法誤り訂正のためのベンチマーク","text":"タイトル： JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction 著者： Courtney Napoles, Keisuke Sakaguchi, Joel Tetreault 会議・出版： EACL 年： 2017 💡 概要 流暢な文法誤り訂正を評価するための開発・評価データを作成 多様な学習者が書いたテキストに対して訂正を行いデータセットを構築 📜 minimal editとfluency editの違い 文法的に誤ったテキストを文法的に正しく書き換えるタスクである文法誤り訂正では訂正方法として(1) minimal editと(2) fluency editの2つの種類がある． minimal edit: 文法的に正しくなるように最低限の訂正を行う．そのため，訂正されたテキストがネイティブにとって流暢ではない可能性がある． fluency edit: ネイティブが自然と感じるテキストになるような訂正や意味がより明解になるような訂正を行う．そのため，minimal editと比較してより多くの書き換えが行われる． 上記の表はminimal editとfluency editそれぞれの訂正例を示している．例えば，ここでは&quot;an impression so well&quot;をより流暢な&quot;such a good impression&quot;に訂正している． 一方で，既存のGEC評価データはminimal editのみでありfluency editの評価データは存在しない．そのため，fluency editに焦点を当てたJHU FLuency-Extended GUG (JFLEG,ジェーフレッグ) コーパスを作成した． 📊 JFLEGの基本情報 GUGデータセット[1]に対して4人のクラウドワーカーが訂正を行うことでJFLEGを作成する．GUGデータセットは3,129文の英語学習者が書いたさまざまなトピックのエッセイにより構成されている．そのため，JFLEGは多様な学習が書いたテキストに対する文法誤り訂正モデルの性能を評価することができる． 上記の表は既存のGECデータ（AESW, FCE, Lang-8とNUCLE）とJFLEGの統計的情報である．# sents.はデータサイズ，Mean chars per sent.は1文に含まれる平均の文字数，Sents. changedは訂正が行われている文の割合，Mean LDは誤文と正文の平均のレーベンシュタイン距離つまり1文が平均的にどれくらい訂正されたかを示している．JFLEGは開発データ754文であり，テストデータ747文から構成されている．この表からJFLEGが既存のコーパスと比較して積極的な書き換えが行われていることがわかる． https://github.com/EducationalTestingService/gug-data ↩︎","link":"/2021/05/14/research_jfleg/"},{"title":"2021年の金子の進捗","text":"💡 概要 2021年の金子の進捗について振り返る 今年はPh.D.を取得したことと新しく岡崎研で働き始めたので主にそれらについて書く 他に今年の論文などについても振り返る 最近、やったことや考えていたかを記録を残しておくことは重要だな〜と思うようになったので、今年から1年の振り返り記事を書く。あえてブログで書くのはそうしないと自分の性格的に丁寧に書かないし、こういう記事の情報が自分に役立ったことがあるので誰かに役立つかもしれないからである。 🎓 Ph.D.になった 今年の3月に都立大で無事Ph.D.を取得した。指導教員の小町先生やこれまで一緒に研究してくださった方々にはたくさんのサポートをしていただき改めて感謝である🙏 自分が支えてもらった分を、下の代に少しずつ返していけたらと思っている。 審査会や公聴会自体は去年の11月や12月にやっていたので体感としてはもっと昔にPh.D.を取得したような気がしていた。自分は新型コロナの関係で、審査会と公聴会どちらもオンラインで行った。ちなみに、自分は公聴会に誰が参加しているかまったく見ていなかったが小町先生によるとそこそこ人が来てくださっていたらしい🙏あと、ありがたいことに博論は情報処理学の研究会推薦博士論文に選ばたので嬉しい☺️ D論書いていたのは1年以上前であり細かいことは全然覚えていないが、D論書いていて感じたことを以下にメモしておくと： 計画的にやる vs. 好奇心の赴くままにやる D論はこれまで自分がやってきた研究の集大成として、トム・ブラウンの漫才のようにそれらを合体させて1つのでっかい論文にする必要がある。D論に向けたアプローチとして大きく分けて以下の2つある気がしている：(1)D論どんな感じにするか大まかな方針を持ってそれにそってやっていく、(2)その時その時に興味がある研究をやる。 自分は典型的な好奇心の赴くままにやるタイプで、文法誤り検出・訂正と公平性という別々のタスクに取り組んでいた。自分が(2)のタイプなのでそっちを深堀りするが、このタイプのメリットは博論書くまでは好き放題研究できることである。一方で、デメリットとしてD論を書く段階で自由にやっていたつけを払うことになる、つまり無関係な研究をこれは計画通りですみたいな顔して1つのテーマに乗っける作業をする必要がある。 そのため、自分はD論で1つのストーリーにすることに一番苦労した。1つのストーリーにしやすいタスクだけで卒業要件を満たしているのであれば、この作業をしなくてすむ方法として、他は博論に含めずにそれだけで書いてしまうというやり方がある。実際、自分は文法誤り検出・訂正だけで卒業要件（論文誌2つまたは論文誌1つと論文誌相当の国際会議1つ）を満たしていたので、100ページ以上にするために分量を増やしてそっちだけでD論を書くこともできた。ただ、研究者としての自分は特に小町先生生とダヌシカ先生のお二人にお世話になった、つまり「小町先生生まれダヌシカ先生育ち」だと思っているので、ダヌシカ先生と一緒にやった公平性の研究も含めたいよねというふんわりした気持ちで頑張って1つの話にまとめる方を選択した（D論に書かなかったら尊敬がないとか全然そういう話ではない）。自分の周囲には(2)のタイプの人のほうが多い印象があり、それも含めてD論の醍醐味だよねみたいな空気感はあったので、今D論書いている方々には「1つの話にまとめられなくて困ったのは君ひとりじゃない頑張って！」という感じである。 🏛 岡崎研での新しい研究生活 Ph.D.になったので4月から東工大の岡崎研で研究員として働き始めた。研究環境としてはかなり最高という感じであり、岡崎研は研究員を絶賛募集中らしいのでもし興味がある方は、いろいろと相談のれると思うので気軽にコンタクトしてもらってOKです！ 以下、岡崎研に来ることになった経緯や研究環境について振り返ると： 岡崎研で働くことになった経緯 そもそも岡崎研で研究員をやることになったのは、進路についてダヌシカ先生にいろいろと相談している中で紹介していただいたことがきっかけである。行くことが確定していたわけではないが卒業の1年前である2020年の春頃には岡崎先生にも受け入れOKをいただいていた。なので、自分の場合はほとんど就活らしい就活をしていない。一応、岡崎研の学振PDとしても採用されたがいろいろと考えた結果辞退して別の形で雇用されることにした。 研究環境 研究室には自分以外に研究者のスタッフとしては教授と助教がいる。まともな研究室のボスには(1)積極的にかかわるタイプと(2)必要以上に干渉せず自由にさせるタイプの2つがあると思うが、うちの教授は(2)だと思われる。どっちが良いとかではなくこれは相性なので、のびのび研究したい自分のような研究者には岡崎研は合っていると思う。一応、補足しておくと干渉しない≠指導しないではなく、うちの教授は相談するとちゃんと助けてくれるので最高という感じである。そして、主著論文を1st tierの国際会議にバリバリ通していて年齢的にも近い助教の方がいるので、雑談形式で気軽に研究のアイデアやNLP界隈についての話しをして、質の高いコメントや知識を教えていただけるのでめちゃめちゃ学びになる。 計算機環境としては研究室のサーバー、TSUBAMEとABCIを使って実験を行っている。GPUについて自分は詳しくないが、良さげなやつをたくさん使えるので計算機が研究のボトルネックになるみたいなことは今のところない。 今年から岡崎研ではメンター制度を導入することになったので、2人のB4の学生と一緒に研究している。自分は学生のときから新入生のために研究テーマを考えてそのテーマを選んだ学生とメンターとして一緒に研究するということをやっていたのでメンターの経験はそこそこある。一方で、新入生のテーマを決めるときに難しいのは、難易度と質のバランスである。ここで難易度とは、そのまま使えるコードの有無などの実装の大変さ、実験量や動かしたら高い確率で成果が出そうかなどの確実性のことを指す。そして、質とは面白い研究であるかや査読ありにちゃんと通りそうかみたいなことである。多くの場合、難易度と質は正の相関がある気がしている。新入生の研究の場合、なるべく早いサイクルでまず研究を経験する、いきなり成果がでないとう研究の闇にのまれない、研究したという自信を持ってもらうために対外発表できる、ようなテーマにしたいと考えると、できる限り難易度を抑えつつ質の高いテーマを考える必要がある。そのため、自分の研究テーマを考えるより制約が多く難しい。ただ、最近の傾向を見ていると自分が考えるテーマは難易度を下げすぎている気がしているので、来年はもうちょっと難易度を上げても良いのでは？と思っている。 📄 研究 主著 今年は全て投稿中であり紹介できないが4本の主著論文を執筆した。そして、2020年に頑張っていた以下の3つの主著論文が国際会議に採択された。共著者のダヌシカ先生には感謝しかない🙏 ダヌシカ先生とは基本的にSlackでやりとし月1くらい（投稿シーズンだともっと頻度が上がる）でzoomを使って相談したりする。自分の場合は「こんなアイデア思いついたんですよね〜」と言ってダヌシカ先生に相談し、そこで詳細について詰めるという始まり方が多い。気軽にアイデアの壁打ちができる心理的安全性ってやっぱ大事だなと思う。 Masahiro Kaneko and Danushka Bollegala. Dictionary-based Debiasing of Pre-trained Word Embeddings. The 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021). , , これはLong paperで4, 3, 4で採択された。 バイアス除去についてこれまでは性別や人種のような特定の属性を対象とする研究がほとんどだったが、実際は特定の属性だけを除去したいというよりは全体的にバイアス消したいよな〜と思っていて、そこから出発した研究である。 単語分散表現の研究は実験が早いので試行錯誤のペースも早くできて個人的には好きであるが、最近は査読者に「BERTでやらないの？」的なことを言われる。 Masahiro Kaneko and Danushka Bollegala. Debiasing Pre-trained Contextualised Embeddings. The 16th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2021). , これもLong paperで3, 3.5, 4で採択された。 単語分散表現のバイアス除去をする研究はあるけど、BERTとかのバイアス除去はほとんどされていないからやってみる？みたいな軽いノリで始めた研究。 自分は最初にサーベイをしたりしないので、後々先行研究をちゃんと調べたら「なんかそこそこBERTとかのバイアス除去あるじゃん」みたいなことがわかったが、差分をちゃんと説明して無事採択された。 話的に面白いというより実験をたくさんやったのが好印象という感じ。 Masahiro Kaneko and Danushka Bollegala. Unmasking the Mask – Evaluating Social Biases in Masked Language Models. Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI 2022). , , Reject, Strong Reject, Strong Accept, Weak Accept, Strong Acceptで採択された。 個人的にマスク良くないという着眼点は気に入っているが査読者によってはモチベーションがまったく伝わらずスコアが割れがちだった。そのため、採択されるまでそこそこ時間がかかった。 自分は2nd tier以上の国際会議やワークショップに締め切りが近い順に投稿していくスタイルなのでどこに採択されるかはそこまで気にしていないが、年に1本は主著で1st tierの本会議に論文が採択されると嬉しいなとは思っているのでAAAI 2022に採択されて良かった。 共著 共著では3本が論文誌、3本が国際会議・ワークショップに採択された。そして、1本プレプリントがある。主著力に感謝である🙏 論文誌 三田雅人, 水本智也, 金子正弘, 永田亮, 乾健太郎。文法誤り訂正モデルの横断評価。 自然言語処理。28巻1号。 甫立健悟, 金子正弘, 勝又智, 小町守. 文法誤り訂正における訂正度を考慮した多様な訂正文の生成。 自然言語処理。28巻2号。 吉村綾馬, 金子正弘, 梶原智之, 小町守. 文法誤り訂正の参照文を用いない自動評価の人手評価への最適化。 自然言語処理。28巻2号。 , 修士のうちに論文誌を書くことで、奨学金が減免になる確率を大幅に上げるというTipsがあるが、2と3は長いこと一緒に研究してくれた修士の学生で、どちらの論文誌の合否も奨学金の減免に大きく関わるものだったので、2つとも無事採択されてよかった。 国際会議 Raj Dabre, Aizhan Imankulova, Masahiro Kaneko. Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation. Proceedings of the 18th Biennial Machine Translation Summit (MT Summit). Aomi Koyama, Kengo Hotate, Masahiro Kaneko and Mamoru Komachi. Comparison of Grammatical Error Correction Using Back-Translation Models. 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop (NAACL SRW). Seiichiro Kondo, Kengo Hotate, Tosho Hirasawa, Masahiro Kaneko and Mamoru Komachi. Sentence Concatenation Approach to Data Augmentation for Neural Machine Translation. 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop (NAACL SRW). プレプリント Raj Dabre, Aizhan Imankulova, Masahiro Kaneko and Abhisek Chakrabarty. Simultaneous Multi-Pivot Neural Machine Translation. arXiv. 学外活動 自然言語処理の論文誌の編集委員に任命された。編集委員は主に査読者を割り当てたり、年1回の論文誌の賞の選考をしたりすることが仕事である。 ブログ 今年の4月から論文以外のアウトプットも頑張らないとなとお思い、とりあえずブログをやり始めた。ここ2〜3年は英語で論文書いたりしているが、国内で主著の研究を発表していないので、ブログがあると日本語で自分の研究を宣伝する場になるのでやってよかったなとは思った。一方で、忙しい時期はほとんど書けなくなるので、今年は夏はまったく更新されていない。コンスタントに更新している小町先生の武蔵野日記はやはりすごい。自分の研究、ツールの使い方や論文紹介をするとそこそこ反響があるようなので、日本のNLP力に貢献できるようにそのあたりの記事を来年も書けるように頑張りたい。 🛒 今年良かったもの 文系研究者になる 「研究する人生」を歩むためのガイドブック [ 石黒 圭 ] Amazonで購入 楽天市場で購入 小町先生の以下のツイートで気になって読んでみた。研究のプロセスや営みについてきちんと言語化して説明されているので、自分が学生などに説明するときに参考になりそう。個人的には7章：つながると8章：生きるが一番知らないことが書かれていた。あと、D学生の環境としてかなり情報系は恵まれているはずで、自分のいる環境が当たり前であると思わないためにも読んでみたが、他分野について知るという観点からも有益であった。 📚 まとめ 今年はいろいろと節目の年で環境の変化があったが、研究的に良い年になったと思う。コロナが落ち着いて来年は久しぶりに学会に現地参加できたら嬉しいな。","link":"/2021/12/31/research_2021/"}],"tags":[{"name":"論文紹介","slug":"論文紹介","link":"/tags/%E8%AB%96%E6%96%87%E7%B4%B9%E4%BB%8B/"},{"name":"文法誤り訂正","slug":"文法誤り訂正","link":"/tags/%E6%96%87%E6%B3%95%E8%AA%A4%E3%82%8A%E8%A8%82%E6%AD%A3/"},{"name":"言語モデル","slug":"言語モデル","link":"/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/"},{"name":"公平性","slug":"公平性","link":"/tags/%E5%85%AC%E5%B9%B3%E6%80%A7/"},{"name":"評価手法","slug":"評価手法","link":"/tags/%E8%A9%95%E4%BE%A1%E6%89%8B%E6%B3%95/"},{"name":"マスク付き言語モデル","slug":"マスク付き言語モデル","link":"/tags/%E3%83%9E%E3%82%B9%E3%82%AF%E4%BB%98%E3%81%8D%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/"},{"name":"データセット","slug":"データセット","link":"/tags/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88/"},{"name":"海外滞在","slug":"海外滞在","link":"/tags/%E6%B5%B7%E5%A4%96%E6%BB%9E%E5%9C%A8/"},{"name":"単語分散表現","slug":"単語分散表現","link":"/tags/%E5%8D%98%E8%AA%9E%E5%88%86%E6%95%A3%E8%A1%A8%E7%8F%BE/"},{"name":"差別的バイアス除去","slug":"差別的バイアス除去","link":"/tags/%E5%B7%AE%E5%88%A5%E7%9A%84%E3%83%90%E3%82%A4%E3%82%A2%E3%82%B9%E9%99%A4%E5%8E%BB/"},{"name":"Tips","slug":"Tips","link":"/tags/Tips/"},{"name":"解釈性","slug":"解釈性","link":"/tags/%E8%A7%A3%E9%87%88%E6%80%A7/"},{"name":"流暢性","slug":"流暢性","link":"/tags/%E6%B5%81%E6%9A%A2%E6%80%A7/"},{"name":"振り返り","slug":"振り返り","link":"/tags/%E6%8C%AF%E3%82%8A%E8%BF%94%E3%82%8A/"}],"categories":[{"name":"💻 プログラミング","slug":"💻-プログラミング","link":"/categories/%F0%9F%92%BB-%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0/"},{"name":"🔎 研究‍","slug":"🔎-研究‍","link":"/categories/%F0%9F%94%8E-%E7%A0%94%E7%A9%B6%E2%80%8D/"},{"name":"🛒 買い物","slug":"🛒-買い物","link":"/categories/%F0%9F%9B%92-%E8%B2%B7%E3%81%84%E7%89%A9/"},{"name":"🏖️ 海外","slug":"🏖️-海外","link":"/categories/%F0%9F%8F%96%EF%B8%8F-%E6%B5%B7%E5%A4%96/"}]}